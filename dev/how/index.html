<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>How does it work? · PPLM.jl</title><link rel="canonical" href="https://adarshkumar712.github.io/PPLM.jl/how/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">PPLM.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>How does it work?</a><ul class="internal"><li><a class="tocitem" href="#Attribute-Models"><span>Attribute Models</span></a></li><li><a class="tocitem" href="#Support"><span>Support</span></a></li><li><a class="tocitem" href="#PPLM"><span>PPLM</span></a></li></ul></li><li><a class="tocitem" href="../gpt2/">GPT2: Tokenization and Generation</a></li><li><a class="tocitem" href="../bow/">Bag Of Words Model</a></li><li><a class="tocitem" href="../discrim/">Discriminator Model</a></li><li><a class="tocitem" href="../discrim_train/">Discriminator Training</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../contact/">Contact Info</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>How does it work?</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>How does it work?</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adarshkumar712/PPLM.jl/blob/master/docs/src/how.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="How-does-PPLM-works?"><a class="docs-heading-anchor" href="#How-does-PPLM-works?">How does PPLM works?</a><a id="How-does-PPLM-works?-1"></a><a class="docs-heading-anchor-permalink" href="#How-does-PPLM-works?" title="Permalink"></a></h1><p>Plug and Play Language Models or PPLM controls the generation of sentences in Large Language Models like GPT2 using gradient based steering towards control attributes. The gradient is evaluated based on Attribute Model being used, which is then used to perturb hidden state or past key values of the model. The perturbation is applied such that it pushes the generation towards the desired attribute.</p><p><img src="../PPLM.png" alt="PPLM"/></p><p><strong>Figure 1</strong> Simplified version of how PPLM works</p><h2 id="Attribute-Models"><a class="docs-heading-anchor" href="#Attribute-Models">Attribute Models</a><a id="Attribute-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Attribute-Models" title="Permalink"></a></h2><p>PPLM.jl provides with the following two Attribute models:</p><h3 id="Bag-Of-Words-or-BoW-Model"><a class="docs-heading-anchor" href="#Bag-Of-Words-or-BoW-Model">Bag Of Words or BoW Model</a><a id="Bag-Of-Words-or-BoW-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Bag-Of-Words-or-BoW-Model" title="Permalink"></a></h3><p>Bag of Words model consist of a list of words that belong to a particular Topic. The loss for this model is evaluated so as to increase probability of words belonging to this list while decreasing the rest, hence, pushing the genration towards desired topic.</p><p>Bag of words available are: <code>legal</code>, <code>military</code>, <code>politics</code>, <code>monsters</code>, <code>science</code>, <code>space</code>, <code>technology</code>, <code>religion</code> and <code>positive_words</code>. Source: <a href="https://github.com/uber-research/PPLM">https://github.com/uber-research/PPLM</a></p><h3 id="Discriminator-Model"><a class="docs-heading-anchor" href="#Discriminator-Model">Discriminator Model</a><a id="Discriminator-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Discriminator-Model" title="Permalink"></a></h3><p>Discriminator Model consist of a trainable ClassifierHead which is basically a Linear layer. The layer is trained for classification of desired attribute. This trained model is then further used to calculate the gradients based on crossentropy loss of generation.</p><p>PPLM.jl currently supports <code>Detoxification</code> model for GPT2-small and <code>sentiment</code> and <code>clickbait</code> for GPT2-medium. (Note: GPT2-medium may give some errors while downloading the model files, because of some file mode issue in Transformers.jl. To rectify, please change the mode of Transformers.jl Huggingface Artifacts.toml file, to allow loading the GPT2 model).</p><p>PPLM.jl further supports training your own Discriminator model and then generate with that model, by providing path to the saved BSON file of model ClassifierHead, along with <code>config_metadata</code>. </p><h2 id="Support"><a class="docs-heading-anchor" href="#Support">Support</a><a id="Support-1"></a><a class="docs-heading-anchor-permalink" href="#Support" title="Permalink"></a></h2><p>PPLM.jl provides support for attribute control based on:</p><ol><li>Hidden State Perturbation</li><li>Past Key Values Perturbation</li></ol><p>For more details, check out the implementation in the repo.</p><h2 id="PPLM"><a class="docs-heading-anchor" href="#PPLM">PPLM</a><a id="PPLM-1"></a><a class="docs-heading-anchor-permalink" href="#PPLM" title="Permalink"></a></h2><p>PPLM struct for hyperparameters for generation looks like this:</p><pre><code class="language-julia">@with_kw struct pplm
    method::String=&quot;BoW&quot;
    perturb::String=&quot;hidden&quot;     # hidden or past -&gt; hidden support BoW only without gradient based change
    bow_list::Vector{String}=[&quot;military&quot;]
    discrim::String=&quot;toxicity&quot;
    embed_size::Int=768
    target_class_id=-1
    file_name::String=&quot;&quot;
    path::String=&quot;&quot;
    stepsize::Float32=0.01      
    max_length::Int=100
    num_iterations::Int=2        # more the number of iterations, more updates, more time to update
    top_k::Int=50
    top_p::Float32=0.8
    temperature::Float32=1.1
    fusion_gm_scale::Float32=0.9
    fusion_kl_scale::Float32=0.01
    cuda::Tuple{Bool, Int64}=(CUDA.has_cuda(), device_id)
    window_length::Int=0          # window length 0 corresponds to infinite length
    gamma::Float32=1.5
end</code></pre><p>These hyperparameters can be tuned as per the desired attribute. Some of the examples of pplm arguments looks like this:</p><pre><code class="language-julia"># bow model
args = pplm(method=&quot;BoW&quot;, bow_list=[&quot;legal&quot;], num_iterations=3)

# discriminator model
args = pplm(method=&quot;Discrim&quot;, perturb=&quot;past&quot;, stepsize=0.02)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../gpt2/">GPT2: Tokenization and Generation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 11 August 2021 13:20">Wednesday 11 August 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
