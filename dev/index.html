<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · PPLM.jl</title><link rel="canonical" href="https://adarshkumar712.github.io/PPLM.jl/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">PPLM.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adarshkumar712/PPLM.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="PPLM"><a class="docs-heading-anchor" href="#PPLM">PPLM</a><a id="PPLM-1"></a><a class="docs-heading-anchor-permalink" href="#PPLM" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/adarshkumar712/PPLM.jl">PPLM</a>.</p><ul><li><a href="#PPLM.GPT2Tokenizer-Tuple{AbstractString}"><code>PPLM.GPT2Tokenizer</code></a></li><li><a href="#PPLM.data_preprocess"><code>PPLM.data_preprocess</code></a></li><li><a href="#PPLM.get_mask-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, Integer}, Tuple{AbstractMatrix{T}, Integer, Integer}} where T"><code>PPLM.get_mask</code></a></li><li><a href="#PPLM.load_cached_data-Tuple{Union{PPLM.DiscriminatorV1, DiscriminatorV2}, Any, Any, PPLM.PretrainedTokenizer}"><code>PPLM.load_cached_data</code></a></li><li><a href="#PPLM.load_data-Tuple{Any, Any, PPLM.PretrainedTokenizer}"><code>PPLM.load_data</code></a></li><li><a href="#PPLM.load_data_from_csv-Tuple{Any}"><code>PPLM.load_data_from_csv</code></a></li><li><a href="#PPLM.pad_seq-Union{Tuple{AbstractVector{T}}, Tuple{T}, Tuple{AbstractVector{T}, Integer}} where T"><code>PPLM.pad_seq</code></a></li><li><a href="#PPLM.register_custom_file-Tuple{Any, Any, Any}"><code>PPLM.register_custom_file</code></a></li><li><a href="#PPLM.save_classifier_head-Tuple{Any}"><code>PPLM.save_classifier_head</code></a></li><li><a href="#PPLM.top_k_logits-Tuple{AbstractArray, Any}"><code>PPLM.top_k_logits</code></a></li><li><a href="#PPLM.truncate_-Tuple{Any, Integer}"><code>PPLM.truncate_</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="PPLM.GPT2Tokenizer-Tuple{AbstractString}" href="#PPLM.GPT2Tokenizer-Tuple{AbstractString}"><code>PPLM.GPT2Tokenizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Example: for vector of texts -&gt; map(x-&gt;encode(tokenizer, x), text<em>vector) or tokenizer.(text</em>vector)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/tokenizer.jl#L54-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.data_preprocess" href="#PPLM.data_preprocess"><code>PPLM.data_preprocess</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">data_preprocess(data_x, data_y, classification_type::String=&quot;Binary&quot;, num_classes::Integer=2; args=nothing)</code></pre><p>Function to preprocess <code>data_x</code> and <code>data_y</code> along with creating mask for the data_x. </p><p>Preprocessing for <code>data_x</code> consist of padding with pad token (expected to be provided as <code>args.pad_token</code>).</p><p>Preprocessing for <code>data_y</code> consist of creating <code>onehotbach</code> for <code>data_y</code> (if <code>classification_type</code> is not &quot;Binary&quot;), for <code>1:num_classes</code> else reshape the data as <code>(1, length(data_y))</code> </p><p>Returns <code>data_x</code>, <code>data_y</code>, <code>mask</code> after pre-processing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L34-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.get_mask-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, Integer}, Tuple{AbstractMatrix{T}, Integer, Integer}} where T" href="#PPLM.get_mask-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, Integer}, Tuple{AbstractMatrix{T}, Integer, Integer}} where T"><code>PPLM.get_mask</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_mask(seq::AbstractMatrix{T}, pad_token::Integer=0, embed_size::Integer=768)</code></pre><p>Function to create mask for sequences against padding, so as to inform the model, that some part of sequenece is padded and hence to be ignored.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L22-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.load_cached_data-Tuple{Union{PPLM.DiscriminatorV1, DiscriminatorV2}, Any, Any, PPLM.PretrainedTokenizer}" href="#PPLM.load_cached_data-Tuple{Union{PPLM.DiscriminatorV1, DiscriminatorV2}, Any, Any, PPLM.PretrainedTokenizer}"><code>PPLM.load_cached_data</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_cached_data(discrim::Union{DiscriminatorV1, DiscriminatorV2}, data_x, data_y, tokenizer::PretrainedTokenizer; truncate::Bool=false, max_length::Integer=256, shuffle::Bool=false, batchsize::Int=4, drop_last::Bool=false, classification_type=&quot;Binary&quot;, num_classes=2, args=nothing)</code></pre><p>Returns a DataLoader with (x, y) which can directly be feeded into classifier layer for training. </p><p>The function first loads the data using <a href="#PPLM.load_data-Tuple{Any, Any, PPLM.PretrainedTokenizer}"><code>load_data</code></a> function with batchsize=1, then passes each batch to the transformer model of <code>discrim</code> after data preprocessing, and then the average representation of the <code>hidden_states</code> are stored in a vector, which are then further loaded into a DataLoader, ready to use for classification training. </p><p><strong>Note</strong>: This functions saves time by cacheing the average representation of hidden states beforehand, avoiding passing the data through model in each epoch of training. This can be done as the model itself is <code>non-trainable</code> while training discriminator classifier head.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L94-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.load_data-Tuple{Any, Any, PPLM.PretrainedTokenizer}" href="#PPLM.load_data-Tuple{Any, Any, PPLM.PretrainedTokenizer}"><code>PPLM.load_data</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_data(data_x, data_y, tokenizer::PretrainedTokenizer;  batchsize::Integer=8, truncate::Bool=false, max_length::Integer=256, shuffle::Bool=false, drop_last::Bool=false, add_eos_start::Bool=true)</code></pre><p>Returns DataLoader for the <code>data_x</code> and <code>data_y</code> after processing the data<em>x, with batchsize=<code>batchsize</code>. The processing consist of tokenization of data</em>x and further truncation to <code>max_len</code> if <code>truncate</code> is set to be true. </p><p>If <code>add_eos_start</code> is set to true, add EOS token of tokenizer to the start. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L74-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.load_data_from_csv-Tuple{Any}" href="#PPLM.load_data_from_csv-Tuple{Any}"><code>PPLM.load_data_from_csv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_data_from_csv(path_to_csv; text_col=&quot;text&quot;, label_col=&quot;label&quot;, delim=&#39;,&#39;, header=1)</code></pre><p>Load the data from a csv file based on the specified <code>text_col</code> column for text and <code>label_col</code> for target label. Returns vectors for <code>text</code> and <code>label</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L140-L144">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.pad_seq-Union{Tuple{AbstractVector{T}}, Tuple{T}, Tuple{AbstractVector{T}, Integer}} where T" href="#PPLM.pad_seq-Union{Tuple{AbstractVector{T}}, Tuple{T}, Tuple{AbstractVector{T}, Integer}} where T"><code>PPLM.pad_seq</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pad_seq(batch::AbstractVector{T}, pad_token::Integer=0)</code></pre><p>Function to add pad tokens in shorter sequence, to make the length of each sequence equal to the <code>max_length</code> ( calculated as <code>max(map(length, batch))</code>) in the batch. Pad token defaults to <code>0</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L5-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.register_custom_file-Tuple{Any, Any, Any}" href="#PPLM.register_custom_file-Tuple{Any, Any, Any}"><code>PPLM.register_custom_file</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Example register<em>custom</em>file(&#39;custom&#39;, &#39;xyz.txt&#39;,&#39;./folder/folder/&#39;)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/artifacts.jl#L29-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.save_classifier_head-Tuple{Any}" href="#PPLM.save_classifier_head-Tuple{Any}"><code>PPLM.save_classifier_head</code></a> — <span class="docstring-category">Method</span></header><section><div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/discriminator.jl#L105-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.top_k_logits-Tuple{AbstractArray, Any}" href="#PPLM.top_k_logits-Tuple{AbstractArray, Any}"><code>PPLM.top_k_logits</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">top_k_logits(logits::AbstractArray, k; prob = false)</code></pre><p>Masks everything but the k top entries as -infinity (1e10). Incase of <code>probs=true</code>, everthing except top-k probabilities are masked to 0.0. <code>logits</code> is expected to be a vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/utils.jl#L9-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PPLM.truncate_-Tuple{Any, Integer}" href="#PPLM.truncate_-Tuple{Any, Integer}"><code>PPLM.truncate_</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">truncate_(x, max_length::Integer)</code></pre><p>Truncate the data to minimum of <code>max_length</code> and length of <code>x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adarshkumar712/PPLM.jl/blob/3719c67445947f82e20f1ff2bfe4030d46d3c5fc/src/data_preprocess.jl#L64-L69">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 20 July 2021 13:29">Tuesday 20 July 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
