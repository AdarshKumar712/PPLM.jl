{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a942f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9beb6ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: load from base: prediction layer not found in state: initialized.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:102\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n",
      "┌ Warning: typename(Transformers.HuggingFace.HGFGPT2Attention) doesn't have field bias.\n",
      "└ @ Transformers.HuggingFace /home/adarshkumar712/.julia/packages/Transformers/3YgSd/src/huggingface/models/models.jl:47\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = PPLM.get_gpt2();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fba1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, label = PPLM.load_data_from_csv(\"./../Datasets/train.csv\";text_col=\"comment_text\", label_col=\"toxic\", delim=\",\"); # replace with appropriate Dataset path, text_col and label_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78f3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim = PPLM.get_discriminator(model; class_size=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919c9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_true = findall(label.==true);\n",
    "ind_false = findall(label.==false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990c7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9c1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1234);\n",
    "true_sample = shuffle(rng, ind_true)[1:15000];\n",
    "false_sample = shuffle(rng, ind_false)[1:15000];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c2a8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = cat(true_sample, false_sample, dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62aad764",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reduced = text[all_samples];\n",
    "label_reduced = label[all_samples];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79611af",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62d1cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPLM.HyperParams\n",
       "  batchsize: Int64 8\n",
       "  eos_token: Int64 50527\n",
       "  pad_token: Int64 0\n",
       "  embed_size: Int64 768\n",
       "  classification_type: String \"MultiClass\"\n",
       "  target_class: Int64 1\n",
       "  num_classes: Int64 2\n",
       "  cached: Bool true\n",
       "  lr: Float64 5.0e-6\n",
       "  epochs: Int64 50\n",
       "  log_interval: Int64 100\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = PPLM.HyperParams(lr=5e-6,classification_type=\"MultiClass\", epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73eae4",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed50928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Cache of data and Data Loader..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing...100%|███████████████████████████████████████| Time: 0:30:03\u001b[39mm30\u001b[39mm\n",
      "\u001b[32mComputing...100%|███████████████████████████████████████| Time: 0:01:41\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting.........\n",
      "\n",
      "Epoch #1 : Step #100 : NLL Loss: 7.163510203361511\n",
      "Epoch #1 : Step #200 : NLL Loss: 6.954627327919006\n",
      "Epoch #1 : Step #300 : NLL Loss: 6.925139118830363\n",
      "Epoch #1 : Step #400 : NLL Loss: 6.951619546711445\n",
      "Epoch #1 : Step #500 : NLL Loss: 6.8917058465480805\n",
      "Epoch #1 : Step #600 : NLL Loss: 6.749353889028232\n",
      "Epoch #1 : Step #700 : NLL Loss: 6.6492555820941925\n",
      "Epoch #1 : Step #800 : NLL Loss: 6.543093764483928\n",
      "Epoch #1 : Step #900 : NLL Loss: 6.435024647315343\n",
      "Epoch #1 : Step #1000 : NLL Loss: 6.337236048698426\n",
      "Epoch #1 : Step #1100 : NLL Loss: 6.212964235219088\n",
      "Epoch #1 : Step #1200 : NLL Loss: 6.116989037195841\n",
      "Epoch #1 : Step #1300 : NLL Loss: 5.9921144500145544\n",
      "Epoch #1 : Step #1400 : NLL Loss: 5.870880446859768\n",
      "Epoch #1 : Step #1500 : NLL Loss: 5.777817563255628\n",
      "Epoch #1 : Step #1600 : NLL Loss: 5.665871746875346\n",
      "Epoch #1 : Step #1700 : NLL Loss: 5.560679710787885\n",
      "Epoch #1 : Step #1800 : NLL Loss: 5.4437543655435245\n",
      "Epoch #1 : Step #1900 : NLL Loss: 5.331730503283049\n",
      "Epoch #1 : Step #2000 : NLL Loss: 5.216301271706819\n",
      "Epoch #1 : Step #2100 : NLL Loss: 5.107390901304426\n",
      "Epoch #1 : Step #2200 : NLL Loss: 4.994827486412092\n",
      "Epoch #1 : Step #2300 : NLL Loss: 4.877674808787263\n",
      "Epoch #1 : Step #2400 : NLL Loss: 4.763870842630665\n",
      "Epoch #1 : Step #2500 : NLL Loss: 4.653222296762467\n",
      "Epoch #1 : Step #2600 : NLL Loss: 4.544153073109113\n",
      "Epoch #1 : Step #2700 : NLL Loss: 4.43874627897033\n",
      "Epoch #1 : Step #2800 : NLL Loss: 4.335391988498824\n",
      "Epoch #1 : Step #2900 : NLL Loss: 4.233204442385969\n",
      "Epoch #1 : Step #3000 : NLL Loss: 4.134946342607339\n",
      "Epoch #1 : Step #3100 : NLL Loss: 4.037274813767403\n",
      "Loss Epoch #1 : 3188 NLL Loss: 3.958641065931978\n",
      "\n",
      "Epoch #2 : Step #100 : NLL Loss: 1.1556224197149276\n",
      "Epoch #2 : Step #200 : NLL Loss: 1.1258007767796516\n",
      "Epoch #2 : Step #300 : NLL Loss: 1.0806193872292837\n",
      "Epoch #2 : Step #400 : NLL Loss: 1.0824862185120583\n",
      "Epoch #2 : Step #500 : NLL Loss: 1.0594448076486587\n",
      "Epoch #2 : Step #600 : NLL Loss: 1.052535934150219\n",
      "Epoch #2 : Step #700 : NLL Loss: 1.0426840115445002\n",
      "Epoch #2 : Step #800 : NLL Loss: 1.034648625329137\n",
      "Epoch #2 : Step #900 : NLL Loss: 1.0212360209888882\n",
      "Epoch #2 : Step #1000 : NLL Loss: 1.015395157814026\n",
      "Epoch #2 : Step #1100 : NLL Loss: 1.008240512880412\n",
      "Epoch #2 : Step #1200 : NLL Loss: 1.0041903583705425\n",
      "Epoch #2 : Step #1300 : NLL Loss: 1.0009160787784137\n",
      "Epoch #2 : Step #1400 : NLL Loss: 0.9970291715860367\n",
      "Epoch #2 : Step #1500 : NLL Loss: 0.9897296286821365\n",
      "Epoch #2 : Step #1600 : NLL Loss: 0.985051466934383\n",
      "Epoch #2 : Step #1700 : NLL Loss: 0.9772864809456994\n",
      "Epoch #2 : Step #1800 : NLL Loss: 0.9744633166988691\n",
      "Epoch #2 : Step #1900 : NLL Loss: 0.972072824678923\n",
      "Epoch #2 : Step #2000 : NLL Loss: 0.9669641628265381\n",
      "Epoch #2 : Step #2100 : NLL Loss: 0.9630599267709823\n",
      "Epoch #2 : Step #2200 : NLL Loss: 0.9596924355626106\n",
      "Epoch #2 : Step #2300 : NLL Loss: 0.9550436894530835\n",
      "Epoch #2 : Step #2400 : NLL Loss: 0.9521659762660662\n",
      "Epoch #2 : Step #2500 : NLL Loss: 0.9483557625532151\n",
      "Epoch #2 : Step #2600 : NLL Loss: 0.9460777220359216\n",
      "Epoch #2 : Step #2700 : NLL Loss: 0.9437550412504762\n",
      "Epoch #2 : Step #2800 : NLL Loss: 0.9398086274734565\n",
      "Epoch #2 : Step #2900 : NLL Loss: 0.9390278642547542\n",
      "Epoch #2 : Step #3000 : NLL Loss: 0.9373018489877383\n",
      "Epoch #2 : Step #3100 : NLL Loss: 0.9332721648100883\n",
      "Loss Epoch #2 : 3188 NLL Loss: 0.929712637361499\n",
      "\n",
      "Epoch #3 : Step #100 : NLL Loss: 0.7972835910320282\n",
      "Epoch #3 : Step #200 : NLL Loss: 0.793795205950737\n",
      "Epoch #3 : Step #300 : NLL Loss: 0.7992730192343394\n",
      "Epoch #3 : Step #400 : NLL Loss: 0.7944511540234089\n",
      "Epoch #3 : Step #500 : NLL Loss: 0.8016999362707138\n",
      "Epoch #3 : Step #600 : NLL Loss: 0.8035280631979307\n",
      "Epoch #3 : Step #700 : NLL Loss: 0.7960310707773481\n",
      "Epoch #3 : Step #800 : NLL Loss: 0.797469984665513\n",
      "Epoch #3 : Step #900 : NLL Loss: 0.7964004670911365\n",
      "Epoch #3 : Step #1000 : NLL Loss: 0.80007417678833\n",
      "Epoch #3 : Step #1100 : NLL Loss: 0.8015183532238006\n",
      "Epoch #3 : Step #1200 : NLL Loss: 0.7978457397222519\n",
      "Epoch #3 : Step #1300 : NLL Loss: 0.7948555906919332\n",
      "Epoch #3 : Step #1400 : NLL Loss: 0.7916045111843518\n",
      "Epoch #3 : Step #1500 : NLL Loss: 0.7877269526720047\n",
      "Epoch #3 : Step #1600 : NLL Loss: 0.7824018447101116\n",
      "Epoch #3 : Step #1700 : NLL Loss: 0.7799964403404909\n",
      "Epoch #3 : Step #1800 : NLL Loss: 0.7773817157414225\n",
      "Epoch #3 : Step #1900 : NLL Loss: 0.777610154136231\n",
      "Epoch #3 : Step #2000 : NLL Loss: 0.7738225024193526\n",
      "Epoch #3 : Step #2100 : NLL Loss: 0.7737994137264433\n",
      "Epoch #3 : Step #2200 : NLL Loss: 0.7718560373512181\n",
      "Epoch #3 : Step #2300 : NLL Loss: 0.7692756412081097\n",
      "Epoch #3 : Step #2400 : NLL Loss: 0.7662570852289597\n",
      "Epoch #3 : Step #2500 : NLL Loss: 0.76563330681324\n",
      "Epoch #3 : Step #2600 : NLL Loss: 0.7634037303466064\n",
      "Epoch #3 : Step #2700 : NLL Loss: 0.7623098319327389\n",
      "Epoch #3 : Step #2800 : NLL Loss: 0.7604668194694179\n",
      "Epoch #3 : Step #2900 : NLL Loss: 0.7595523121541944\n",
      "Epoch #3 : Step #3000 : NLL Loss: 0.7562214829027653\n",
      "Epoch #3 : Step #3100 : NLL Loss: 0.7540366085402427\n",
      "Loss Epoch #3 : 3188 NLL Loss: 0.7521319552470779\n",
      "\n",
      "Epoch #4 : Step #100 : NLL Loss: 0.6140203630924225\n",
      "Epoch #4 : Step #200 : NLL Loss: 0.6482955652475357\n",
      "Epoch #4 : Step #300 : NLL Loss: 0.661699864268303\n",
      "Epoch #4 : Step #400 : NLL Loss: 0.663299326300621\n",
      "Epoch #4 : Step #500 : NLL Loss: 0.6641308064460755\n",
      "Epoch #4 : Step #600 : NLL Loss: 0.6650056803723177\n",
      "Epoch #4 : Step #700 : NLL Loss: 0.6599276411959103\n",
      "Epoch #4 : Step #800 : NLL Loss: 0.6636744292452932\n",
      "Epoch #4 : Step #900 : NLL Loss: 0.6595289853877492\n",
      "Epoch #4 : Step #1000 : NLL Loss: 0.6611804541647435\n",
      "Epoch #4 : Step #1100 : NLL Loss: 0.6555329434167255\n",
      "Epoch #4 : Step #1200 : NLL Loss: 0.6534824214378993\n",
      "Epoch #4 : Step #1300 : NLL Loss: 0.6581959820252199\n",
      "Epoch #4 : Step #1400 : NLL Loss: 0.6588069177099637\n",
      "Epoch #4 : Step #1500 : NLL Loss: 0.6567474673390389\n",
      "Epoch #4 : Step #1600 : NLL Loss: 0.6571393170021474\n",
      "Epoch #4 : Step #1700 : NLL Loss: 0.6543292737182449\n",
      "Epoch #4 : Step #1800 : NLL Loss: 0.653442959503995\n",
      "Epoch #4 : Step #1900 : NLL Loss: 0.6537548940903262\n",
      "Epoch #4 : Step #2000 : NLL Loss: 0.6504282857477665\n",
      "Epoch #4 : Step #2100 : NLL Loss: 0.6476310480066708\n",
      "Epoch #4 : Step #2200 : NLL Loss: 0.6481033552370288\n",
      "Epoch #4 : Step #2300 : NLL Loss: 0.6445231241635654\n",
      "Epoch #4 : Step #2400 : NLL Loss: 0.6415997854123513\n",
      "Epoch #4 : Step #2500 : NLL Loss: 0.6409562238454819\n",
      "Epoch #4 : Step #2600 : NLL Loss: 0.6428218091221957\n",
      "Epoch #4 : Step #2700 : NLL Loss: 0.6419168620860135\n",
      "Epoch #4 : Step #2800 : NLL Loss: 0.6422518619894981\n",
      "Epoch #4 : Step #2900 : NLL Loss: 0.6412370804671583\n",
      "Epoch #4 : Step #3000 : NLL Loss: 0.6387026112874349\n",
      "Epoch #4 : Step #3100 : NLL Loss: 0.6368284343519518\n",
      "Loss Epoch #4 : 3188 NLL Loss: 0.6359246888547351\n",
      "\n",
      "Epoch #5 : Step #100 : NLL Loss: 0.623414676785469\n",
      "Epoch #5 : Step #200 : NLL Loss: 0.5960563427209854\n",
      "Epoch #5 : Step #300 : NLL Loss: 0.5870445609092713\n",
      "Epoch #5 : Step #400 : NLL Loss: 0.5888463938236237\n",
      "Epoch #5 : Step #500 : NLL Loss: 0.5825466835498809\n",
      "Epoch #5 : Step #600 : NLL Loss: 0.5795244276026885\n",
      "Epoch #5 : Step #700 : NLL Loss: 0.5766134401304381\n",
      "Epoch #5 : Step #800 : NLL Loss: 0.5779935237392784\n",
      "Epoch #5 : Step #900 : NLL Loss: 0.5768418159418636\n",
      "Epoch #5 : Step #1000 : NLL Loss: 0.5778994836807251\n",
      "Epoch #5 : Step #1100 : NLL Loss: 0.5759950322725557\n",
      "Epoch #5 : Step #1200 : NLL Loss: 0.5779630828648805\n",
      "Epoch #5 : Step #1300 : NLL Loss: 0.578014300763607\n",
      "Epoch #5 : Step #1400 : NLL Loss: 0.580982963591814\n",
      "Epoch #5 : Step #1500 : NLL Loss: 0.5778561558127403\n",
      "Epoch #5 : Step #1600 : NLL Loss: 0.5768800576590002\n",
      "Epoch #5 : Step #1700 : NLL Loss: 0.5742340396257007\n",
      "Epoch #5 : Step #1800 : NLL Loss: 0.5721102677782377\n",
      "Epoch #5 : Step #1900 : NLL Loss: 0.5712959082816776\n",
      "Epoch #5 : Step #2000 : NLL Loss: 0.569221877798438\n",
      "Epoch #5 : Step #2100 : NLL Loss: 0.5677034622572718\n",
      "Epoch #5 : Step #2200 : NLL Loss: 0.566713810021227\n",
      "Epoch #5 : Step #2300 : NLL Loss: 0.5662838427657666\n",
      "Epoch #5 : Step #2400 : NLL Loss: 0.5668299945816397\n",
      "Epoch #5 : Step #2500 : NLL Loss: 0.5655150479912758\n",
      "Epoch #5 : Step #2600 : NLL Loss: 0.5630817381235269\n",
      "Epoch #5 : Step #2700 : NLL Loss: 0.5622141588617254\n",
      "Epoch #5 : Step #2800 : NLL Loss: 0.5613457729560988\n",
      "Epoch #5 : Step #2900 : NLL Loss: 0.5600962354088652\n",
      "Epoch #5 : Step #3000 : NLL Loss: 0.5587154027422269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5 : Step #3100 : NLL Loss: 0.5576759557954727\n",
      "Loss Epoch #5 : 3188 NLL Loss: 0.556316845801424\n",
      "\n",
      "Epoch #6 : Step #100 : NLL Loss: 0.5357412496209144\n",
      "Epoch #6 : Step #200 : NLL Loss: 0.5495168827474117\n",
      "Epoch #6 : Step #300 : NLL Loss: 0.5425607279936473\n",
      "Epoch #6 : Step #400 : NLL Loss: 0.5425075631588697\n",
      "Epoch #6 : Step #500 : NLL Loss: 0.5390195402503014\n",
      "Epoch #6 : Step #600 : NLL Loss: 0.532209989875555\n",
      "Epoch #6 : Step #700 : NLL Loss: 0.5357000788194792\n",
      "Epoch #6 : Step #800 : NLL Loss: 0.5293076775968075\n",
      "Epoch #6 : Step #900 : NLL Loss: 0.5243838971190983\n",
      "Epoch #6 : Step #1000 : NLL Loss: 0.5209631095230579\n",
      "Epoch #6 : Step #1100 : NLL Loss: 0.5208315500887958\n",
      "Epoch #6 : Step #1200 : NLL Loss: 0.5198536813507477\n",
      "Epoch #6 : Step #1300 : NLL Loss: 0.5197337271158512\n",
      "Epoch #6 : Step #1400 : NLL Loss: 0.5169973816190447\n",
      "Epoch #6 : Step #1500 : NLL Loss: 0.5153426946997642\n",
      "Epoch #6 : Step #1600 : NLL Loss: 0.513513153064996\n",
      "Epoch #6 : Step #1700 : NLL Loss: 0.5125086650953573\n",
      "Epoch #6 : Step #1800 : NLL Loss: 0.5121832786997159\n",
      "Epoch #6 : Step #1900 : NLL Loss: 0.5128710044998872\n",
      "Epoch #6 : Step #2000 : NLL Loss: 0.5109126212149858\n",
      "Epoch #6 : Step #2100 : NLL Loss: 0.5093579099149931\n",
      "Epoch #6 : Step #2200 : NLL Loss: 0.5074218369478529\n",
      "Epoch #6 : Step #2300 : NLL Loss: 0.5094435996724211\n",
      "Epoch #6 : Step #2400 : NLL Loss: 0.5079769582053025\n",
      "Epoch #6 : Step #2500 : NLL Loss: 0.5057780066609383\n",
      "Epoch #6 : Step #2600 : NLL Loss: 0.5060353663449104\n",
      "Epoch #6 : Step #2700 : NLL Loss: 0.5057203401349208\n",
      "Epoch #6 : Step #2800 : NLL Loss: 0.5038814136598792\n",
      "Epoch #6 : Step #2900 : NLL Loss: 0.5019987362417682\n",
      "Epoch #6 : Step #3000 : NLL Loss: 0.4999859954416752\n",
      "Epoch #6 : Step #3100 : NLL Loss: 0.49869663239486756\n",
      "Loss Epoch #6 : 3188 NLL Loss: 0.4977716784760674\n",
      "\n",
      "Epoch #7 : Step #100 : NLL Loss: 0.4622401723265648\n",
      "Epoch #7 : Step #200 : NLL Loss: 0.4607907010614872\n",
      "Epoch #7 : Step #300 : NLL Loss: 0.457540779709816\n",
      "Epoch #7 : Step #400 : NLL Loss: 0.45595381945371627\n",
      "Epoch #7 : Step #500 : NLL Loss: 0.4518784577846527\n",
      "Epoch #7 : Step #600 : NLL Loss: 0.452734002918005\n",
      "Epoch #7 : Step #700 : NLL Loss: 0.4575713248763766\n",
      "Epoch #7 : Step #800 : NLL Loss: 0.4608255436271429\n",
      "Epoch #7 : Step #900 : NLL Loss: 0.4657488187485271\n",
      "Epoch #7 : Step #1000 : NLL Loss: 0.4652005489468575\n",
      "Epoch #7 : Step #1100 : NLL Loss: 0.46668986688960684\n",
      "Epoch #7 : Step #1200 : NLL Loss: 0.4679612834751606\n",
      "Epoch #7 : Step #1300 : NLL Loss: 0.46756986980254833\n",
      "Epoch #7 : Step #1400 : NLL Loss: 0.46486975552780285\n",
      "Epoch #7 : Step #1500 : NLL Loss: 0.4637772838274638\n",
      "Epoch #7 : Step #1600 : NLL Loss: 0.4620927360840142\n",
      "Epoch #7 : Step #1700 : NLL Loss: 0.4637763903596822\n",
      "Epoch #7 : Step #1800 : NLL Loss: 0.46224030094014273\n",
      "Epoch #7 : Step #1900 : NLL Loss: 0.46085883815037576\n",
      "Epoch #7 : Step #2000 : NLL Loss: 0.46051674331724646\n",
      "Epoch #7 : Step #2100 : NLL Loss: 0.45988823978673843\n",
      "Epoch #7 : Step #2200 : NLL Loss: 0.45847233265638354\n",
      "Epoch #7 : Step #2300 : NLL Loss: 0.4571883899491766\n",
      "Epoch #7 : Step #2400 : NLL Loss: 0.4573297381773591\n",
      "Epoch #7 : Step #2500 : NLL Loss: 0.4568435337662697\n",
      "Epoch #7 : Step #2600 : NLL Loss: 0.45629891882722196\n",
      "Epoch #7 : Step #2700 : NLL Loss: 0.45594825231366687\n",
      "Epoch #7 : Step #2800 : NLL Loss: 0.4556809220356601\n",
      "Epoch #7 : Step #2900 : NLL Loss: 0.4549263154329925\n",
      "Epoch #7 : Step #3000 : NLL Loss: 0.45369871801137923\n",
      "Epoch #7 : Step #3100 : NLL Loss: 0.4532676352320179\n",
      "Loss Epoch #7 : 3188 NLL Loss: 0.45238827186703234\n",
      "\n",
      "Epoch #8 : Step #100 : NLL Loss: 0.42487311333417893\n",
      "Epoch #8 : Step #200 : NLL Loss: 0.42050122022628783\n",
      "Epoch #8 : Step #300 : NLL Loss: 0.4281817110379537\n",
      "Epoch #8 : Step #400 : NLL Loss: 0.4328943056613207\n",
      "Epoch #8 : Step #500 : NLL Loss: 0.4320848660469055\n",
      "Epoch #8 : Step #600 : NLL Loss: 0.4313772367934386\n",
      "Epoch #8 : Step #700 : NLL Loss: 0.4315540355869702\n",
      "Epoch #8 : Step #800 : NLL Loss: 0.43263512846082447\n",
      "Epoch #8 : Step #900 : NLL Loss: 0.43342059658633336\n",
      "Epoch #8 : Step #1000 : NLL Loss: 0.4331150008440018\n",
      "Epoch #8 : Step #1100 : NLL Loss: 0.43055293782190845\n",
      "Epoch #8 : Step #1200 : NLL Loss: 0.429459666510423\n",
      "Epoch #8 : Step #1300 : NLL Loss: 0.42817483159211966\n",
      "Epoch #8 : Step #1400 : NLL Loss: 0.4263599322949137\n",
      "Epoch #8 : Step #1500 : NLL Loss: 0.4273060350616773\n",
      "Epoch #8 : Step #1600 : NLL Loss: 0.42655929569154977\n",
      "Epoch #8 : Step #1700 : NLL Loss: 0.4247314056578804\n",
      "Epoch #8 : Step #1800 : NLL Loss: 0.4237419358392556\n",
      "Epoch #8 : Step #1900 : NLL Loss: 0.42401580034117947\n",
      "Epoch #8 : Step #2000 : NLL Loss: 0.42362877415120603\n",
      "Epoch #8 : Step #2100 : NLL Loss: 0.4226572390113558\n",
      "Epoch #8 : Step #2200 : NLL Loss: 0.42254164361140945\n",
      "Epoch #8 : Step #2300 : NLL Loss: 0.422836888121522\n",
      "Epoch #8 : Step #2400 : NLL Loss: 0.42224451327075563\n",
      "Epoch #8 : Step #2500 : NLL Loss: 0.4212877765059471\n",
      "Epoch #8 : Step #2600 : NLL Loss: 0.4208852163874186\n",
      "Epoch #8 : Step #2700 : NLL Loss: 0.4208937198585934\n",
      "Epoch #8 : Step #2800 : NLL Loss: 0.4195280312214579\n",
      "Epoch #8 : Step #2900 : NLL Loss: 0.4197205990758435\n",
      "Epoch #8 : Step #3000 : NLL Loss: 0.4191537990967433\n",
      "Epoch #8 : Step #3100 : NLL Loss: 0.41810952201004953\n",
      "Loss Epoch #8 : 3188 NLL Loss: 0.4175139068341913\n",
      "\n",
      "Epoch #9 : Step #100 : NLL Loss: 0.3924076735973358\n",
      "Epoch #9 : Step #200 : NLL Loss: 0.3930469550192356\n",
      "Epoch #9 : Step #300 : NLL Loss: 0.39636601304014524\n",
      "Epoch #9 : Step #400 : NLL Loss: 0.3947722363844514\n",
      "Epoch #9 : Step #500 : NLL Loss: 0.39723750099539756\n",
      "Epoch #9 : Step #600 : NLL Loss: 0.3993596344937881\n",
      "Epoch #9 : Step #700 : NLL Loss: 0.3999469555914402\n",
      "Epoch #9 : Step #800 : NLL Loss: 0.39792247718200086\n",
      "Epoch #9 : Step #900 : NLL Loss: 0.39818410096897017\n",
      "Epoch #9 : Step #1000 : NLL Loss: 0.39825851072371005\n",
      "Epoch #9 : Step #1100 : NLL Loss: 0.3996490766378966\n",
      "Epoch #9 : Step #1200 : NLL Loss: 0.39895971925308304\n",
      "Epoch #9 : Step #1300 : NLL Loss: 0.39960419142475495\n",
      "Epoch #9 : Step #1400 : NLL Loss: 0.40112256410930835\n",
      "Epoch #9 : Step #1500 : NLL Loss: 0.40051826064785323\n",
      "Epoch #9 : Step #1600 : NLL Loss: 0.4002259957883507\n",
      "Epoch #9 : Step #1700 : NLL Loss: 0.39891863369766406\n",
      "Epoch #9 : Step #1800 : NLL Loss: 0.39689629669818616\n",
      "Epoch #9 : Step #1900 : NLL Loss: 0.396582980289271\n",
      "Epoch #9 : Step #2000 : NLL Loss: 0.3955383758172393\n",
      "Epoch #9 : Step #2100 : NLL Loss: 0.3947356603897753\n",
      "Epoch #9 : Step #2200 : NLL Loss: 0.39507917270741677\n",
      "Epoch #9 : Step #2300 : NLL Loss: 0.39485682131803557\n",
      "Epoch #9 : Step #2400 : NLL Loss: 0.3945955694032212\n",
      "Epoch #9 : Step #2500 : NLL Loss: 0.3941179030239582\n",
      "Epoch #9 : Step #2600 : NLL Loss: 0.3945739359867114\n",
      "Epoch #9 : Step #2700 : NLL Loss: 0.39403753123349616\n",
      "Epoch #9 : Step #2800 : NLL Loss: 0.3929795032473547\n",
      "Epoch #9 : Step #2900 : NLL Loss: 0.3918106438836147\n",
      "Epoch #9 : Step #3000 : NLL Loss: 0.3915615103294452\n",
      "Epoch #9 : Step #3100 : NLL Loss: 0.392273216983003\n",
      "Loss Epoch #9 : 3188 NLL Loss: 0.39172983801966926\n",
      "\n",
      "Epoch #10 : Step #100 : NLL Loss: 0.40907622516155245\n",
      "Epoch #10 : Step #200 : NLL Loss: 0.4007229420542717\n",
      "Epoch #10 : Step #300 : NLL Loss: 0.38613408396641413\n",
      "Epoch #10 : Step #400 : NLL Loss: 0.37647804893553255\n",
      "Epoch #10 : Step #500 : NLL Loss: 0.37444581258296966\n",
      "Epoch #10 : Step #600 : NLL Loss: 0.3722956689198812\n",
      "Epoch #10 : Step #700 : NLL Loss: 0.37235541058438165\n",
      "Epoch #10 : Step #800 : NLL Loss: 0.3720499311760068\n",
      "Epoch #10 : Step #900 : NLL Loss: 0.3705018829968241\n",
      "Epoch #10 : Step #1000 : NLL Loss: 0.3728254496455193\n",
      "Epoch #10 : Step #1100 : NLL Loss: 0.3719080354408784\n",
      "Epoch #10 : Step #1200 : NLL Loss: 0.37137621064980825\n",
      "Epoch #10 : Step #1300 : NLL Loss: 0.37443155103004894\n",
      "Epoch #10 : Step #1400 : NLL Loss: 0.3753716614416667\n",
      "Epoch #10 : Step #1500 : NLL Loss: 0.37469857120513916\n",
      "Epoch #10 : Step #1600 : NLL Loss: 0.3759305360540748\n",
      "Epoch #10 : Step #1700 : NLL Loss: 0.3745174484393176\n",
      "Epoch #10 : Step #1800 : NLL Loss: 0.37341808829042644\n",
      "Epoch #10 : Step #1900 : NLL Loss: 0.37297958811647014\n",
      "Epoch #10 : Step #2000 : NLL Loss: 0.37279805923998355\n",
      "Epoch #10 : Step #2100 : NLL Loss: 0.37345740305525915\n",
      "Epoch #10 : Step #2200 : NLL Loss: 0.37235060412775384\n",
      "Epoch #10 : Step #2300 : NLL Loss: 0.37288333138693935\n",
      "Epoch #10 : Step #2400 : NLL Loss: 0.3729265191902717\n",
      "Epoch #10 : Step #2500 : NLL Loss: 0.3729173331141472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10 : Step #2600 : NLL Loss: 0.37314182400703433\n",
      "Epoch #10 : Step #2700 : NLL Loss: 0.37259868385615175\n",
      "Epoch #10 : Step #2800 : NLL Loss: 0.37281958829079354\n",
      "Epoch #10 : Step #2900 : NLL Loss: 0.3727307544802797\n",
      "Epoch #10 : Step #3000 : NLL Loss: 0.37223725534478824\n",
      "Epoch #10 : Step #3100 : NLL Loss: 0.37242506270447084\n",
      "Loss Epoch #10 : 3188 NLL Loss: 0.3727460496940906\n",
      "\n",
      "Epoch #11 : Step #100 : NLL Loss: 0.3812038683891296\n",
      "Epoch #11 : Step #200 : NLL Loss: 0.3669163554906845\n",
      "Epoch #11 : Step #300 : NLL Loss: 0.36636526574691136\n",
      "Epoch #11 : Step #400 : NLL Loss: 0.3627946697920561\n",
      "Epoch #11 : Step #500 : NLL Loss: 0.3594117218852043\n",
      "Epoch #11 : Step #600 : NLL Loss: 0.35777595673998197\n",
      "Epoch #11 : Step #700 : NLL Loss: 0.36045928678342276\n",
      "Epoch #11 : Step #800 : NLL Loss: 0.36709382981061933\n",
      "Epoch #11 : Step #900 : NLL Loss: 0.3684851606355773\n",
      "Epoch #11 : Step #1000 : NLL Loss: 0.36693612244725227\n",
      "Epoch #11 : Step #1100 : NLL Loss: 0.3672542225230824\n",
      "Epoch #11 : Step #1200 : NLL Loss: 0.36637739663322766\n",
      "Epoch #11 : Step #1300 : NLL Loss: 0.3663835587180578\n",
      "Epoch #11 : Step #1400 : NLL Loss: 0.3634445383506162\n",
      "Epoch #11 : Step #1500 : NLL Loss: 0.365017415702343\n",
      "Epoch #11 : Step #1600 : NLL Loss: 0.3627191518619657\n",
      "Epoch #11 : Step #1700 : NLL Loss: 0.3632999460486805\n",
      "Epoch #11 : Step #1800 : NLL Loss: 0.3633554076651732\n",
      "Epoch #11 : Step #1900 : NLL Loss: 0.362947155096029\n",
      "Epoch #11 : Step #2000 : NLL Loss: 0.3619457017183304\n",
      "Epoch #11 : Step #2100 : NLL Loss: 0.36222867352621896\n",
      "Epoch #11 : Step #2200 : NLL Loss: 0.3627275426550345\n",
      "Epoch #11 : Step #2300 : NLL Loss: 0.36244254780852275\n",
      "Epoch #11 : Step #2400 : NLL Loss: 0.36232474859803915\n",
      "Epoch #11 : Step #2500 : NLL Loss: 0.362092660343647\n",
      "Epoch #11 : Step #2600 : NLL Loss: 0.36164733137075716\n",
      "Epoch #11 : Step #2700 : NLL Loss: 0.36132667458719675\n",
      "Epoch #11 : Step #2800 : NLL Loss: 0.36091987766325473\n",
      "Epoch #11 : Step #2900 : NLL Loss: 0.360065485054049\n",
      "Epoch #11 : Step #3000 : NLL Loss: 0.359031061142683\n",
      "Epoch #11 : Step #3100 : NLL Loss: 0.35848358847441214\n",
      "Loss Epoch #11 : 3188 NLL Loss: 0.3582667464874171\n",
      "\n",
      "Epoch #12 : Step #100 : NLL Loss: 0.36505766212940216\n",
      "Epoch #12 : Step #200 : NLL Loss: 0.35690956518054007\n",
      "Epoch #12 : Step #300 : NLL Loss: 0.3564772117137909\n",
      "Epoch #12 : Step #400 : NLL Loss: 0.35816006489098073\n",
      "Epoch #12 : Step #500 : NLL Loss: 0.35783303874731065\n",
      "Epoch #12 : Step #600 : NLL Loss: 0.3567809202770392\n",
      "Epoch #12 : Step #700 : NLL Loss: 0.35666311740875245\n",
      "Epoch #12 : Step #800 : NLL Loss: 0.35375672807916997\n",
      "Epoch #12 : Step #900 : NLL Loss: 0.35426689497298663\n",
      "Epoch #12 : Step #1000 : NLL Loss: 0.3540739458054304\n",
      "Epoch #12 : Step #1100 : NLL Loss: 0.35421925966035234\n",
      "Epoch #12 : Step #1200 : NLL Loss: 0.3531889707967639\n",
      "Epoch #12 : Step #1300 : NLL Loss: 0.35248134886989224\n",
      "Epoch #12 : Step #1400 : NLL Loss: 0.3521066559531859\n",
      "Epoch #12 : Step #1500 : NLL Loss: 0.3511007991532485\n",
      "Epoch #12 : Step #1600 : NLL Loss: 0.35073706092312934\n",
      "Epoch #12 : Step #1700 : NLL Loss: 0.35015114647500656\n",
      "Epoch #12 : Step #1800 : NLL Loss: 0.3500745018654399\n",
      "Epoch #12 : Step #1900 : NLL Loss: 0.34980126396605843\n",
      "Epoch #12 : Step #2000 : NLL Loss: 0.3480009074509144\n",
      "Epoch #12 : Step #2100 : NLL Loss: 0.34799347969747724\n",
      "Epoch #12 : Step #2200 : NLL Loss: 0.34787059527906505\n",
      "Epoch #12 : Step #2300 : NLL Loss: 0.34669016451939294\n",
      "Epoch #12 : Step #2400 : NLL Loss: 0.3459976040075223\n",
      "Epoch #12 : Step #2500 : NLL Loss: 0.34602913744449615\n",
      "Epoch #12 : Step #2600 : NLL Loss: 0.34519405185030055\n",
      "Epoch #12 : Step #2700 : NLL Loss: 0.34525085541937084\n",
      "Epoch #12 : Step #2800 : NLL Loss: 0.34705755911767483\n",
      "Epoch #12 : Step #2900 : NLL Loss: 0.3475636460246711\n",
      "Epoch #12 : Step #3000 : NLL Loss: 0.34789037344853085\n",
      "Epoch #12 : Step #3100 : NLL Loss: 0.34764119865432863\n",
      "Loss Epoch #12 : 3188 NLL Loss: 0.3471039425175043\n",
      "\n",
      "Epoch #13 : Step #100 : NLL Loss: 0.30929082721471785\n",
      "Epoch #13 : Step #200 : NLL Loss: 0.3257758179306984\n",
      "Epoch #13 : Step #300 : NLL Loss: 0.333524518708388\n",
      "Epoch #13 : Step #400 : NLL Loss: 0.34133465379476546\n",
      "Epoch #13 : Step #500 : NLL Loss: 0.3383789509534836\n",
      "Epoch #13 : Step #600 : NLL Loss: 0.33790379067262016\n",
      "Epoch #13 : Step #700 : NLL Loss: 0.3406580268059458\n",
      "Epoch #13 : Step #800 : NLL Loss: 0.3403741970658302\n",
      "Epoch #13 : Step #900 : NLL Loss: 0.33906766947772765\n",
      "Epoch #13 : Step #1000 : NLL Loss: 0.34089486074447634\n",
      "Epoch #13 : Step #1100 : NLL Loss: 0.3439069361307404\n",
      "Epoch #13 : Step #1200 : NLL Loss: 0.3455553509046634\n",
      "Epoch #13 : Step #1300 : NLL Loss: 0.34430321986858664\n",
      "Epoch #13 : Step #1400 : NLL Loss: 0.34401439628430774\n",
      "Epoch #13 : Step #1500 : NLL Loss: 0.34522467880447705\n",
      "Epoch #13 : Step #1600 : NLL Loss: 0.3433998898137361\n",
      "Epoch #13 : Step #1700 : NLL Loss: 0.3435485344336313\n",
      "Epoch #13 : Step #1800 : NLL Loss: 0.34237689866787857\n",
      "Epoch #13 : Step #1900 : NLL Loss: 0.34288649920570224\n",
      "Epoch #13 : Step #2000 : NLL Loss: 0.34285060650855304\n",
      "Epoch #13 : Step #2100 : NLL Loss: 0.3424056693414847\n",
      "Epoch #13 : Step #2200 : NLL Loss: 0.3420055346258662\n",
      "Epoch #13 : Step #2300 : NLL Loss: 0.3412536533565625\n",
      "Epoch #13 : Step #2400 : NLL Loss: 0.3402858998688559\n",
      "Epoch #13 : Step #2500 : NLL Loss: 0.3401041989862919\n",
      "Epoch #13 : Step #2600 : NLL Loss: 0.3397469679495463\n",
      "Epoch #13 : Step #2700 : NLL Loss: 0.3390765382901386\n",
      "Epoch #13 : Step #2800 : NLL Loss: 0.33950609624918016\n",
      "Epoch #13 : Step #2900 : NLL Loss: 0.3390969757324663\n",
      "Epoch #13 : Step #3000 : NLL Loss: 0.3395480857938528\n",
      "Epoch #13 : Step #3100 : NLL Loss: 0.33840330886744685\n",
      "Loss Epoch #13 : 3188 NLL Loss: 0.33787346871071955\n",
      "\n",
      "Epoch #14 : Step #100 : NLL Loss: 0.32881579160690305\n",
      "Epoch #14 : Step #200 : NLL Loss: 0.3292249056696892\n",
      "Epoch #14 : Step #300 : NLL Loss: 0.32705540224909785\n",
      "Epoch #14 : Step #400 : NLL Loss: 0.328235132060945\n",
      "Epoch #14 : Step #500 : NLL Loss: 0.3271785827577114\n",
      "Epoch #14 : Step #600 : NLL Loss: 0.32696764551103114\n",
      "Epoch #14 : Step #700 : NLL Loss: 0.3271437278177057\n",
      "Epoch #14 : Step #800 : NLL Loss: 0.32608420817181466\n",
      "Epoch #14 : Step #900 : NLL Loss: 0.3258477435343795\n",
      "Epoch #14 : Step #1000 : NLL Loss: 0.3255665866881609\n",
      "Epoch #14 : Step #1100 : NLL Loss: 0.3258898407898166\n",
      "Epoch #14 : Step #1200 : NLL Loss: 0.3296715089057883\n",
      "Epoch #14 : Step #1300 : NLL Loss: 0.3314256496956715\n",
      "Epoch #14 : Step #1400 : NLL Loss: 0.3300646593208824\n",
      "Epoch #14 : Step #1500 : NLL Loss: 0.33138748173912363\n",
      "Epoch #14 : Step #1600 : NLL Loss: 0.3317349848803133\n",
      "Epoch #14 : Step #1700 : NLL Loss: 0.33306434996864376\n",
      "Epoch #14 : Step #1800 : NLL Loss: 0.3336881102869908\n",
      "Epoch #14 : Step #1900 : NLL Loss: 0.33170021222610224\n",
      "Epoch #14 : Step #2000 : NLL Loss: 0.33200749092549087\n",
      "Epoch #14 : Step #2100 : NLL Loss: 0.33178451635298273\n",
      "Epoch #14 : Step #2200 : NLL Loss: 0.33270047097720884\n",
      "Epoch #14 : Step #2300 : NLL Loss: 0.33167952631478725\n",
      "Epoch #14 : Step #2400 : NLL Loss: 0.3322824152745307\n",
      "Epoch #14 : Step #2500 : NLL Loss: 0.3321086896121502\n",
      "Epoch #14 : Step #2600 : NLL Loss: 0.3321968122686331\n",
      "Epoch #14 : Step #2700 : NLL Loss: 0.3331667641743466\n",
      "Epoch #14 : Step #2800 : NLL Loss: 0.33265574754881005\n",
      "Epoch #14 : Step #2900 : NLL Loss: 0.3326393100465166\n",
      "Epoch #14 : Step #3000 : NLL Loss: 0.3316560632834832\n",
      "Epoch #14 : Step #3100 : NLL Loss: 0.33119220421679557\n",
      "Loss Epoch #14 : 3188 NLL Loss: 0.33046221734495507\n",
      "\n",
      "Epoch #15 : Step #100 : NLL Loss: 0.32138088047504426\n",
      "Epoch #15 : Step #200 : NLL Loss: 0.3272022941708565\n",
      "Epoch #15 : Step #300 : NLL Loss: 0.32514718631903333\n",
      "Epoch #15 : Step #400 : NLL Loss: 0.33289916105568407\n",
      "Epoch #15 : Step #500 : NLL Loss: 0.32902638548612595\n",
      "Epoch #15 : Step #600 : NLL Loss: 0.33136063928405446\n",
      "Epoch #15 : Step #700 : NLL Loss: 0.3332848565493311\n",
      "Epoch #15 : Step #800 : NLL Loss: 0.3344341488927603\n",
      "Epoch #15 : Step #900 : NLL Loss: 0.33410499890645345\n",
      "Epoch #15 : Step #1000 : NLL Loss: 0.33075626522302626\n",
      "Epoch #15 : Step #1100 : NLL Loss: 0.32935590435158124\n",
      "Epoch #15 : Step #1200 : NLL Loss: 0.32938534279664355\n",
      "Epoch #15 : Step #1300 : NLL Loss: 0.32887631581379817\n",
      "Epoch #15 : Step #1400 : NLL Loss: 0.32598996047462736\n",
      "Epoch #15 : Step #1500 : NLL Loss: 0.3244782142241796\n",
      "Epoch #15 : Step #1600 : NLL Loss: 0.3259213533811271\n",
      "Epoch #15 : Step #1700 : NLL Loss: 0.3266332784996313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15 : Step #1800 : NLL Loss: 0.3273751143117746\n",
      "Epoch #15 : Step #1900 : NLL Loss: 0.3284014664355077\n",
      "Epoch #15 : Step #2000 : NLL Loss: 0.32743355253338813\n",
      "Epoch #15 : Step #2100 : NLL Loss: 0.32632057777472906\n",
      "Epoch #15 : Step #2200 : NLL Loss: 0.3258289921961047\n",
      "Epoch #15 : Step #2300 : NLL Loss: 0.32585090849710546\n",
      "Epoch #15 : Step #2400 : NLL Loss: 0.325235951282084\n",
      "Epoch #15 : Step #2500 : NLL Loss: 0.32513225458860395\n",
      "Epoch #15 : Step #2600 : NLL Loss: 0.32574180060854324\n",
      "Epoch #15 : Step #2700 : NLL Loss: 0.3260982674801791\n",
      "Epoch #15 : Step #2800 : NLL Loss: 0.32594206839799883\n",
      "Epoch #15 : Step #2900 : NLL Loss: 0.32556734549588173\n",
      "Epoch #15 : Step #3000 : NLL Loss: 0.3241639296511809\n",
      "Epoch #15 : Step #3100 : NLL Loss: 0.3241835959592173\n",
      "Loss Epoch #15 : 3188 NLL Loss: 0.32401208587953706\n",
      "\n",
      "Epoch #16 : Step #100 : NLL Loss: 0.33489894509315493\n",
      "Epoch #16 : Step #200 : NLL Loss: 0.32716145619750026\n",
      "Epoch #16 : Step #300 : NLL Loss: 0.3277201009790103\n",
      "Epoch #16 : Step #400 : NLL Loss: 0.330922619625926\n",
      "Epoch #16 : Step #500 : NLL Loss: 0.33207774949073793\n",
      "Epoch #16 : Step #600 : NLL Loss: 0.3272401411831379\n",
      "Epoch #16 : Step #700 : NLL Loss: 0.3312115510446685\n",
      "Epoch #16 : Step #800 : NLL Loss: 0.3303985211625695\n",
      "Epoch #16 : Step #900 : NLL Loss: 0.32773148311509026\n",
      "Epoch #16 : Step #1000 : NLL Loss: 0.32559693324565886\n",
      "Epoch #16 : Step #1100 : NLL Loss: 0.32628297307274556\n",
      "Epoch #16 : Step #1200 : NLL Loss: 0.32346964232623576\n",
      "Epoch #16 : Step #1300 : NLL Loss: 0.3212918293246856\n",
      "Epoch #16 : Step #1400 : NLL Loss: 0.3215940778170313\n",
      "Epoch #16 : Step #1500 : NLL Loss: 0.3204910307029883\n",
      "Epoch #16 : Step #1600 : NLL Loss: 0.3208694421034306\n",
      "Epoch #16 : Step #1700 : NLL Loss: 0.32106749787926675\n",
      "Epoch #16 : Step #1800 : NLL Loss: 0.322129351819555\n",
      "Epoch #16 : Step #1900 : NLL Loss: 0.3216386833237974\n",
      "Epoch #16 : Step #2000 : NLL Loss: 0.3218683727309108\n",
      "Epoch #16 : Step #2100 : NLL Loss: 0.3215245188417889\n",
      "Epoch #16 : Step #2200 : NLL Loss: 0.32223361592401156\n",
      "Epoch #16 : Step #2300 : NLL Loss: 0.32224872786065806\n",
      "Epoch #16 : Step #2400 : NLL Loss: 0.32148895602673294\n",
      "Epoch #16 : Step #2500 : NLL Loss: 0.3214748918771744\n",
      "Epoch #16 : Step #2600 : NLL Loss: 0.32064209465797133\n",
      "Epoch #16 : Step #2700 : NLL Loss: 0.3195342367225223\n",
      "Epoch #16 : Step #2800 : NLL Loss: 0.31908254204051834\n",
      "Epoch #16 : Step #2900 : NLL Loss: 0.31896439551279465\n",
      "Epoch #16 : Step #3000 : NLL Loss: 0.31907829305529595\n",
      "Epoch #16 : Step #3100 : NLL Loss: 0.3190427837737145\n",
      "Loss Epoch #16 : 3188 NLL Loss: 0.31866605499457834\n",
      "\n",
      "Epoch #17 : Step #100 : NLL Loss: 0.33421735882759096\n",
      "Epoch #17 : Step #200 : NLL Loss: 0.32427374333143233\n",
      "Epoch #17 : Step #300 : NLL Loss: 0.32205368469158807\n",
      "Epoch #17 : Step #400 : NLL Loss: 0.32380738273262977\n",
      "Epoch #17 : Step #500 : NLL Loss: 0.31934384754300116\n",
      "Epoch #17 : Step #600 : NLL Loss: 0.3188346449782451\n",
      "Epoch #17 : Step #700 : NLL Loss: 0.3209545926323959\n",
      "Epoch #17 : Step #800 : NLL Loss: 0.3198304087109864\n",
      "Epoch #17 : Step #900 : NLL Loss: 0.3210907259749042\n",
      "Epoch #17 : Step #1000 : NLL Loss: 0.3173152162581682\n",
      "Epoch #17 : Step #1100 : NLL Loss: 0.31414699536832896\n",
      "Epoch #17 : Step #1200 : NLL Loss: 0.3144953178241849\n",
      "Epoch #17 : Step #1300 : NLL Loss: 0.31530642295112976\n",
      "Epoch #17 : Step #1400 : NLL Loss: 0.31627097139401095\n",
      "Epoch #17 : Step #1500 : NLL Loss: 0.31757094894846283\n",
      "Epoch #17 : Step #1600 : NLL Loss: 0.3171560836676508\n",
      "Epoch #17 : Step #1700 : NLL Loss: 0.31607550536008444\n",
      "Epoch #17 : Step #1800 : NLL Loss: 0.31509175021615293\n",
      "Epoch #17 : Step #1900 : NLL Loss: 0.31543571319235\n",
      "Epoch #17 : Step #2000 : NLL Loss: 0.31558427756279706\n",
      "Epoch #17 : Step #2100 : NLL Loss: 0.3162442188816411\n",
      "Epoch #17 : Step #2200 : NLL Loss: 0.3158831340413202\n",
      "Epoch #17 : Step #2300 : NLL Loss: 0.3154890614942364\n",
      "Epoch #17 : Step #2400 : NLL Loss: 0.314572480811427\n",
      "Epoch #17 : Step #2500 : NLL Loss: 0.3153579912722111\n",
      "Epoch #17 : Step #2600 : NLL Loss: 0.31522839541045516\n",
      "Epoch #17 : Step #2700 : NLL Loss: 0.31475851348704764\n",
      "Epoch #17 : Step #2800 : NLL Loss: 0.3150339694480811\n",
      "Epoch #17 : Step #2900 : NLL Loss: 0.31482716656450566\n",
      "Epoch #17 : Step #3000 : NLL Loss: 0.3144462441454331\n",
      "Epoch #17 : Step #3100 : NLL Loss: 0.31408768733182263\n",
      "Loss Epoch #17 : 3188 NLL Loss: 0.31404848251412326\n",
      "\n",
      "Epoch #18 : Step #100 : NLL Loss: 0.3094799792766571\n",
      "Epoch #18 : Step #200 : NLL Loss: 0.30768589168787003\n",
      "Epoch #18 : Step #300 : NLL Loss: 0.299931869606177\n",
      "Epoch #18 : Step #400 : NLL Loss: 0.30293430425226686\n",
      "Epoch #18 : Step #500 : NLL Loss: 0.3080006870627403\n",
      "Epoch #18 : Step #600 : NLL Loss: 0.30755549197395643\n",
      "Epoch #18 : Step #700 : NLL Loss: 0.31127217956951686\n",
      "Epoch #18 : Step #800 : NLL Loss: 0.3107300368696451\n",
      "Epoch #18 : Step #900 : NLL Loss: 0.3123943867617183\n",
      "Epoch #18 : Step #1000 : NLL Loss: 0.31002490532398225\n",
      "Epoch #18 : Step #1100 : NLL Loss: 0.31053350892933934\n",
      "Epoch #18 : Step #1200 : NLL Loss: 0.3102843137830496\n",
      "Epoch #18 : Step #1300 : NLL Loss: 0.3097785317668548\n",
      "Epoch #18 : Step #1400 : NLL Loss: 0.3102369299318109\n",
      "Epoch #18 : Step #1500 : NLL Loss: 0.3107256294290225\n",
      "Epoch #18 : Step #1600 : NLL Loss: 0.31071299377828837\n",
      "Epoch #18 : Step #1700 : NLL Loss: 0.30986491716959896\n",
      "Epoch #18 : Step #1800 : NLL Loss: 0.3108956434329351\n",
      "Epoch #18 : Step #1900 : NLL Loss: 0.31141688691942315\n",
      "Epoch #18 : Step #2000 : NLL Loss: 0.31116338743269445\n",
      "Epoch #18 : Step #2100 : NLL Loss: 0.3119604208497774\n",
      "Epoch #18 : Step #2200 : NLL Loss: 0.3121948393908414\n",
      "Epoch #18 : Step #2300 : NLL Loss: 0.31262069203283477\n",
      "Epoch #18 : Step #2400 : NLL Loss: 0.3127387438838681\n",
      "Epoch #18 : Step #2500 : NLL Loss: 0.31268512585163116\n",
      "Epoch #18 : Step #2600 : NLL Loss: 0.31276698766992644\n",
      "Epoch #18 : Step #2700 : NLL Loss: 0.31185027883008676\n",
      "Epoch #18 : Step #2800 : NLL Loss: 0.31166048098887716\n",
      "Epoch #18 : Step #2900 : NLL Loss: 0.3109236781247731\n",
      "Epoch #18 : Step #3000 : NLL Loss: 0.310084829390049\n",
      "Epoch #18 : Step #3100 : NLL Loss: 0.31025184735175104\n",
      "Loss Epoch #18 : 3188 NLL Loss: 0.31002744584527786\n",
      "\n",
      "Epoch #19 : Step #100 : NLL Loss: 0.3059450769424438\n",
      "Epoch #19 : Step #200 : NLL Loss: 0.3083011710643768\n",
      "Epoch #19 : Step #300 : NLL Loss: 0.3152080597480138\n",
      "Epoch #19 : Step #400 : NLL Loss: 0.313125586733222\n",
      "Epoch #19 : Step #500 : NLL Loss: 0.3137354162931442\n",
      "Epoch #19 : Step #600 : NLL Loss: 0.3136466673016548\n",
      "Epoch #19 : Step #700 : NLL Loss: 0.31357171995299205\n",
      "Epoch #19 : Step #800 : NLL Loss: 0.31286091659218074\n",
      "Epoch #19 : Step #900 : NLL Loss: 0.3143493850032488\n",
      "Epoch #19 : Step #1000 : NLL Loss: 0.31543665698170664\n",
      "Epoch #19 : Step #1100 : NLL Loss: 0.3156859870661389\n",
      "Epoch #19 : Step #1200 : NLL Loss: 0.31540419896443683\n",
      "Epoch #19 : Step #1300 : NLL Loss: 0.31407329802329725\n",
      "Epoch #19 : Step #1400 : NLL Loss: 0.3120142206549644\n",
      "Epoch #19 : Step #1500 : NLL Loss: 0.3122943482995033\n",
      "Epoch #19 : Step #1600 : NLL Loss: 0.31020879273302854\n",
      "Epoch #19 : Step #1700 : NLL Loss: 0.3102466189773644\n",
      "Epoch #19 : Step #1800 : NLL Loss: 0.31134497186375987\n",
      "Epoch #19 : Step #1900 : NLL Loss: 0.3106781442777107\n",
      "Epoch #19 : Step #2000 : NLL Loss: 0.30944319608062504\n",
      "Epoch #19 : Step #2100 : NLL Loss: 0.308458743329559\n",
      "Epoch #19 : Step #2200 : NLL Loss: 0.30838346127082\n",
      "Epoch #19 : Step #2300 : NLL Loss: 0.30723206456588664\n",
      "Epoch #19 : Step #2400 : NLL Loss: 0.30752840388566255\n",
      "Epoch #19 : Step #2500 : NLL Loss: 0.3067181808948517\n",
      "Epoch #19 : Step #2600 : NLL Loss: 0.3078069508419587\n",
      "Epoch #19 : Step #2700 : NLL Loss: 0.30767589266653417\n",
      "Epoch #19 : Step #2800 : NLL Loss: 0.30781492321618964\n",
      "Epoch #19 : Step #2900 : NLL Loss: 0.30711659125212964\n",
      "Epoch #19 : Step #3000 : NLL Loss: 0.3074066679080327\n",
      "Epoch #19 : Step #3100 : NLL Loss: 0.30721021741628646\n",
      "Loss Epoch #19 : 3188 NLL Loss: 0.3065115829539419\n",
      "\n",
      "Epoch #20 : Step #100 : NLL Loss: 0.29056437641382216\n",
      "Epoch #20 : Step #200 : NLL Loss: 0.3038318382203579\n",
      "Epoch #20 : Step #300 : NLL Loss: 0.3124881405631701\n",
      "Epoch #20 : Step #400 : NLL Loss: 0.31281225092709064\n",
      "Epoch #20 : Step #500 : NLL Loss: 0.31028836941719057\n",
      "Epoch #20 : Step #600 : NLL Loss: 0.3128959018488725\n",
      "Epoch #20 : Step #700 : NLL Loss: 0.30866920207227977\n",
      "Epoch #20 : Step #800 : NLL Loss: 0.3098242738097906\n",
      "Epoch #20 : Step #900 : NLL Loss: 0.31151226086748973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20 : Step #1000 : NLL Loss: 0.31040266782045367\n",
      "Epoch #20 : Step #1100 : NLL Loss: 0.30957008161328053\n",
      "Epoch #20 : Step #1200 : NLL Loss: 0.3091075915594896\n",
      "Epoch #20 : Step #1300 : NLL Loss: 0.30495149749975936\n",
      "Epoch #20 : Step #1400 : NLL Loss: 0.30489591794354576\n",
      "Epoch #20 : Step #1500 : NLL Loss: 0.30438322861989336\n",
      "Epoch #20 : Step #1600 : NLL Loss: 0.30620865631848576\n",
      "Epoch #20 : Step #1700 : NLL Loss: 0.3047206532253939\n",
      "Epoch #20 : Step #1800 : NLL Loss: 0.30374657726950116\n",
      "Epoch #20 : Step #1900 : NLL Loss: 0.30439563123803387\n",
      "Epoch #20 : Step #2000 : NLL Loss: 0.3050907711833715\n",
      "Epoch #20 : Step #2100 : NLL Loss: 0.30504528870185216\n",
      "Epoch #20 : Step #2200 : NLL Loss: 0.3058267635784366\n",
      "Epoch #20 : Step #2300 : NLL Loss: 0.3056421649456024\n",
      "Epoch #20 : Step #2400 : NLL Loss: 0.3053807270651062\n",
      "Epoch #20 : Step #2500 : NLL Loss: 0.30509249984025955\n",
      "Epoch #20 : Step #2600 : NLL Loss: 0.30579238708202655\n",
      "Epoch #20 : Step #2700 : NLL Loss: 0.30536843972073663\n",
      "Epoch #20 : Step #2800 : NLL Loss: 0.30448061573718277\n",
      "Epoch #20 : Step #2900 : NLL Loss: 0.3043017192544608\n",
      "Epoch #20 : Step #3000 : NLL Loss: 0.30484309621651967\n",
      "Epoch #20 : Step #3100 : NLL Loss: 0.30369849452087955\n",
      "Loss Epoch #20 : 3188 NLL Loss: 0.3031684868645339\n",
      "\n",
      "Epoch #21 : Step #100 : NLL Loss: 0.2827631151676178\n",
      "Epoch #21 : Step #200 : NLL Loss: 0.3068952079117298\n",
      "Epoch #21 : Step #300 : NLL Loss: 0.3069459949930509\n",
      "Epoch #21 : Step #400 : NLL Loss: 0.30554592438042166\n",
      "Epoch #21 : Step #500 : NLL Loss: 0.3079913141727447\n",
      "Epoch #21 : Step #600 : NLL Loss: 0.30811316341161726\n",
      "Epoch #21 : Step #700 : NLL Loss: 0.30542797829423635\n",
      "Epoch #21 : Step #800 : NLL Loss: 0.30304063819348814\n",
      "Epoch #21 : Step #900 : NLL Loss: 0.29943484551376764\n",
      "Epoch #21 : Step #1000 : NLL Loss: 0.3006946865618229\n",
      "Epoch #21 : Step #1100 : NLL Loss: 0.30160159945487974\n",
      "Epoch #21 : Step #1200 : NLL Loss: 0.30349656626582144\n",
      "Epoch #21 : Step #1300 : NLL Loss: 0.30336943351305445\n",
      "Epoch #21 : Step #1400 : NLL Loss: 0.30331950798630714\n",
      "Epoch #21 : Step #1500 : NLL Loss: 0.30272939083973566\n",
      "Epoch #21 : Step #1600 : NLL Loss: 0.30290219506248833\n",
      "Epoch #21 : Step #1700 : NLL Loss: 0.3012652546868605\n",
      "Epoch #21 : Step #1800 : NLL Loss: 0.299766789343622\n",
      "Epoch #21 : Step #1900 : NLL Loss: 0.29926561256772594\n",
      "Epoch #21 : Step #2000 : NLL Loss: 0.2992328952252865\n",
      "Epoch #21 : Step #2100 : NLL Loss: 0.2990595008361907\n",
      "Epoch #21 : Step #2200 : NLL Loss: 0.29963226380673325\n",
      "Epoch #21 : Step #2300 : NLL Loss: 0.30038672053295634\n",
      "Epoch #21 : Step #2400 : NLL Loss: 0.2998437810316682\n",
      "Epoch #21 : Step #2500 : NLL Loss: 0.29965867899656295\n",
      "Epoch #21 : Step #2600 : NLL Loss: 0.2997525328856248\n",
      "Epoch #21 : Step #2700 : NLL Loss: 0.299647616788193\n",
      "Epoch #21 : Step #2800 : NLL Loss: 0.2998142817297152\n",
      "Epoch #21 : Step #2900 : NLL Loss: 0.30023762080176125\n",
      "Epoch #21 : Step #3000 : NLL Loss: 0.30046179797748723\n",
      "Epoch #21 : Step #3100 : NLL Loss: 0.30036026536457\n",
      "Loss Epoch #21 : 3188 NLL Loss: 0.3006225379564831\n",
      "\n",
      "Epoch #22 : Step #100 : NLL Loss: 0.31477556616067887\n",
      "Epoch #22 : Step #200 : NLL Loss: 0.3068443259596825\n",
      "Epoch #22 : Step #300 : NLL Loss: 0.30009159445762634\n",
      "Epoch #22 : Step #400 : NLL Loss: 0.3060251965373755\n",
      "Epoch #22 : Step #500 : NLL Loss: 0.3004907799959183\n",
      "Epoch #22 : Step #600 : NLL Loss: 0.3034578897555669\n",
      "Epoch #22 : Step #700 : NLL Loss: 0.30262201109102793\n",
      "Epoch #22 : Step #800 : NLL Loss: 0.30708388581871987\n",
      "Epoch #22 : Step #900 : NLL Loss: 0.3072184831235144\n",
      "Epoch #22 : Step #1000 : NLL Loss: 0.3075484758615494\n",
      "Epoch #22 : Step #1100 : NLL Loss: 0.30748484137383375\n",
      "Epoch #22 : Step #1200 : NLL Loss: 0.3063547311971585\n",
      "Epoch #22 : Step #1300 : NLL Loss: 0.3053223094802636\n",
      "Epoch #22 : Step #1400 : NLL Loss: 0.3053241873213223\n",
      "Epoch #22 : Step #1500 : NLL Loss: 0.30449554705619813\n",
      "Epoch #22 : Step #1600 : NLL Loss: 0.30431918628513815\n",
      "Epoch #22 : Step #1700 : NLL Loss: 0.30489359627751744\n",
      "Epoch #22 : Step #1800 : NLL Loss: 0.30515874703725177\n",
      "Epoch #22 : Step #1900 : NLL Loss: 0.30400531423719307\n",
      "Epoch #22 : Step #2000 : NLL Loss: 0.30369746915996076\n",
      "Epoch #22 : Step #2100 : NLL Loss: 0.3018625973377909\n",
      "Epoch #22 : Step #2200 : NLL Loss: 0.301655968983065\n",
      "Epoch #22 : Step #2300 : NLL Loss: 0.3008866004192311\n",
      "Epoch #22 : Step #2400 : NLL Loss: 0.30154466760655246\n",
      "Epoch #22 : Step #2500 : NLL Loss: 0.30061766184568406\n",
      "Epoch #22 : Step #2600 : NLL Loss: 0.3000219298899174\n",
      "Epoch #22 : Step #2700 : NLL Loss: 0.29952468810258087\n",
      "Epoch #22 : Step #2800 : NLL Loss: 0.2990916200514351\n",
      "Epoch #22 : Step #2900 : NLL Loss: 0.29842302502229295\n",
      "Epoch #22 : Step #3000 : NLL Loss: 0.29800256514549256\n",
      "Epoch #22 : Step #3100 : NLL Loss: 0.2984183498736351\n",
      "Loss Epoch #22 : 3188 NLL Loss: 0.29799733669911904\n",
      "\n",
      "Epoch #23 : Step #100 : NLL Loss: 0.3096072560548782\n",
      "Epoch #23 : Step #200 : NLL Loss: 0.31512671411037446\n",
      "Epoch #23 : Step #300 : NLL Loss: 0.3126477998495102\n",
      "Epoch #23 : Step #400 : NLL Loss: 0.3092732376605272\n",
      "Epoch #23 : Step #500 : NLL Loss: 0.3075718730688095\n",
      "Epoch #23 : Step #600 : NLL Loss: 0.30693627292911213\n",
      "Epoch #23 : Step #700 : NLL Loss: 0.307960085272789\n",
      "Epoch #23 : Step #800 : NLL Loss: 0.30583032324910164\n",
      "Epoch #23 : Step #900 : NLL Loss: 0.301453507343928\n",
      "Epoch #23 : Step #1000 : NLL Loss: 0.3008992304503918\n",
      "Epoch #23 : Step #1100 : NLL Loss: 0.2995740402015773\n",
      "Epoch #23 : Step #1200 : NLL Loss: 0.2985503089676301\n",
      "Epoch #23 : Step #1300 : NLL Loss: 0.2988205107817283\n",
      "Epoch #23 : Step #1400 : NLL Loss: 0.2988355782840933\n",
      "Epoch #23 : Step #1500 : NLL Loss: 0.297691471238931\n",
      "Epoch #23 : Step #1600 : NLL Loss: 0.2979428075067699\n",
      "Epoch #23 : Step #1700 : NLL Loss: 0.2949830995237126\n",
      "Epoch #23 : Step #1800 : NLL Loss: 0.2932624080777168\n",
      "Epoch #23 : Step #1900 : NLL Loss: 0.2946258481866435\n",
      "Epoch #23 : Step #2000 : NLL Loss: 0.29474958980083465\n",
      "Epoch #23 : Step #2100 : NLL Loss: 0.2945639692885535\n",
      "Epoch #23 : Step #2200 : NLL Loss: 0.2954130038483576\n",
      "Epoch #23 : Step #2300 : NLL Loss: 0.2945966270825137\n",
      "Epoch #23 : Step #2400 : NLL Loss: 0.2943793236836791\n",
      "Epoch #23 : Step #2500 : NLL Loss: 0.29441423448324205\n",
      "Epoch #23 : Step #2600 : NLL Loss: 0.29514497190713884\n",
      "Epoch #23 : Step #2700 : NLL Loss: 0.29460904135748195\n",
      "Epoch #23 : Step #2800 : NLL Loss: 0.2954238220197814\n",
      "Epoch #23 : Step #2900 : NLL Loss: 0.295830905879366\n",
      "Epoch #23 : Step #3000 : NLL Loss: 0.29587136080861093\n",
      "Epoch #23 : Step #3100 : NLL Loss: 0.29587356455864444\n",
      "Loss Epoch #23 : 3188 NLL Loss: 0.295712139284521\n",
      "\n",
      "Epoch #24 : Step #100 : NLL Loss: 0.29508610218763354\n",
      "Epoch #24 : Step #200 : NLL Loss: 0.29202892512083056\n",
      "Epoch #24 : Step #300 : NLL Loss: 0.28846745828787485\n",
      "Epoch #24 : Step #400 : NLL Loss: 0.28855847790837286\n",
      "Epoch #24 : Step #500 : NLL Loss: 0.29285316652059556\n",
      "Epoch #24 : Step #600 : NLL Loss: 0.2963893495500088\n",
      "Epoch #24 : Step #700 : NLL Loss: 0.29741491564682554\n",
      "Epoch #24 : Step #800 : NLL Loss: 0.29973224747926\n",
      "Epoch #24 : Step #900 : NLL Loss: 0.29952409025695587\n",
      "Epoch #24 : Step #1000 : NLL Loss: 0.29619959834218024\n",
      "Epoch #24 : Step #1100 : NLL Loss: 0.296097653020512\n",
      "Epoch #24 : Step #1200 : NLL Loss: 0.2962516903877258\n",
      "Epoch #24 : Step #1300 : NLL Loss: 0.2964604861461199\n",
      "Epoch #24 : Step #1400 : NLL Loss: 0.2981805589582239\n",
      "Epoch #24 : Step #1500 : NLL Loss: 0.298416963160038\n",
      "Epoch #24 : Step #1600 : NLL Loss: 0.2974777312763035\n",
      "Epoch #24 : Step #1700 : NLL Loss: 0.2975176562982447\n",
      "Epoch #24 : Step #1800 : NLL Loss: 0.2968891966342926\n",
      "Epoch #24 : Step #1900 : NLL Loss: 0.2953776393281786\n",
      "Epoch #24 : Step #2000 : NLL Loss: 0.29574945832788946\n",
      "Epoch #24 : Step #2100 : NLL Loss: 0.29523900118612106\n",
      "Epoch #24 : Step #2200 : NLL Loss: 0.2955319121344523\n",
      "Epoch #24 : Step #2300 : NLL Loss: 0.29664239902859146\n",
      "Epoch #24 : Step #2400 : NLL Loss: 0.29602073433498544\n",
      "Epoch #24 : Step #2500 : NLL Loss: 0.29579288516044616\n",
      "Epoch #24 : Step #2600 : NLL Loss: 0.2953888005591356\n",
      "Epoch #24 : Step #2700 : NLL Loss: 0.2947530146550249\n",
      "Epoch #24 : Step #2800 : NLL Loss: 0.29473609028118\n",
      "Epoch #24 : Step #2900 : NLL Loss: 0.2942914328801221\n",
      "Epoch #24 : Step #3000 : NLL Loss: 0.2942298343876998\n",
      "Epoch #24 : Step #3100 : NLL Loss: 0.2941621631383896\n",
      "Loss Epoch #24 : 3188 NLL Loss: 0.2934404913350061\n",
      "\n",
      "Epoch #25 : Step #100 : NLL Loss: 0.27918853640556335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #25 : Step #200 : NLL Loss: 0.29179689347743987\n",
      "Epoch #25 : Step #300 : NLL Loss: 0.2943960209687551\n",
      "Epoch #25 : Step #400 : NLL Loss: 0.292045584321022\n",
      "Epoch #25 : Step #500 : NLL Loss: 0.29750975394248963\n",
      "Epoch #25 : Step #600 : NLL Loss: 0.3005290762086709\n",
      "Epoch #25 : Step #700 : NLL Loss: 0.297941215974944\n",
      "Epoch #25 : Step #800 : NLL Loss: 0.2963453292474151\n",
      "Epoch #25 : Step #900 : NLL Loss: 0.2976997677816285\n",
      "Epoch #25 : Step #1000 : NLL Loss: 0.2937749388217926\n",
      "Epoch #25 : Step #1100 : NLL Loss: 0.29388104184107344\n",
      "Epoch #25 : Step #1200 : NLL Loss: 0.29173501456777257\n",
      "Epoch #25 : Step #1300 : NLL Loss: 0.2904206247971608\n",
      "Epoch #25 : Step #1400 : NLL Loss: 0.2905227564913886\n",
      "Epoch #25 : Step #1500 : NLL Loss: 0.2911762976646423\n",
      "Epoch #25 : Step #1600 : NLL Loss: 0.2900549514591694\n",
      "Epoch #25 : Step #1700 : NLL Loss: 0.29213635164148666\n",
      "Epoch #25 : Step #1800 : NLL Loss: 0.2928163202603658\n",
      "Epoch #25 : Step #1900 : NLL Loss: 0.2920858454390576\n",
      "Epoch #25 : Step #2000 : NLL Loss: 0.2911638991236687\n",
      "Epoch #25 : Step #2100 : NLL Loss: 0.2900036699289367\n",
      "Epoch #25 : Step #2200 : NLL Loss: 0.2903595355694944\n",
      "Epoch #25 : Step #2300 : NLL Loss: 0.29080911138783333\n",
      "Epoch #25 : Step #2400 : NLL Loss: 0.2904908253066242\n",
      "Epoch #25 : Step #2500 : NLL Loss: 0.2910801147282124\n",
      "Epoch #25 : Step #2600 : NLL Loss: 0.29058083531948237\n",
      "Epoch #25 : Step #2700 : NLL Loss: 0.2910861082209481\n",
      "Epoch #25 : Step #2800 : NLL Loss: 0.29039758957922457\n",
      "Epoch #25 : Step #2900 : NLL Loss: 0.29050371591387125\n",
      "Epoch #25 : Step #3000 : NLL Loss: 0.29054345295826595\n",
      "Epoch #25 : Step #3100 : NLL Loss: 0.29193892730820564\n",
      "Loss Epoch #25 : 3188 NLL Loss: 0.2915711126651339\n",
      "\n",
      "Epoch #26 : Step #100 : NLL Loss: 0.2832847934961319\n",
      "Epoch #26 : Step #200 : NLL Loss: 0.2748599757254124\n",
      "Epoch #26 : Step #300 : NLL Loss: 0.27519451240698495\n",
      "Epoch #26 : Step #400 : NLL Loss: 0.2776263615489006\n",
      "Epoch #26 : Step #500 : NLL Loss: 0.2747110535502434\n",
      "Epoch #26 : Step #600 : NLL Loss: 0.27516440163056055\n",
      "Epoch #26 : Step #700 : NLL Loss: 0.2821765681675502\n",
      "Epoch #26 : Step #800 : NLL Loss: 0.28113051384687426\n",
      "Epoch #26 : Step #900 : NLL Loss: 0.28179952674441866\n",
      "Epoch #26 : Step #1000 : NLL Loss: 0.2820956546068192\n",
      "Epoch #26 : Step #1100 : NLL Loss: 0.28284594503316013\n",
      "Epoch #26 : Step #1200 : NLL Loss: 0.2837699689219395\n",
      "Epoch #26 : Step #1300 : NLL Loss: 0.2834537471257723\n",
      "Epoch #26 : Step #1400 : NLL Loss: 0.2855191463657788\n",
      "Epoch #26 : Step #1500 : NLL Loss: 0.2847053417166074\n",
      "Epoch #26 : Step #1600 : NLL Loss: 0.2850608926452696\n",
      "Epoch #26 : Step #1700 : NLL Loss: 0.2861591407481362\n",
      "Epoch #26 : Step #1800 : NLL Loss: 0.2868318314353625\n",
      "Epoch #26 : Step #1900 : NLL Loss: 0.2878713804169705\n",
      "Epoch #26 : Step #2000 : NLL Loss: 0.2874831402748823\n",
      "Epoch #26 : Step #2100 : NLL Loss: 0.2883514670247123\n",
      "Epoch #26 : Step #2200 : NLL Loss: 0.28855492384596304\n",
      "Epoch #26 : Step #2300 : NLL Loss: 0.2895769716604896\n",
      "Epoch #26 : Step #2400 : NLL Loss: 0.287866595685482\n",
      "Epoch #26 : Step #2500 : NLL Loss: 0.28794264414310455\n",
      "Epoch #26 : Step #2600 : NLL Loss: 0.288090797238625\n",
      "Epoch #26 : Step #2700 : NLL Loss: 0.2873149190677537\n",
      "Epoch #26 : Step #2800 : NLL Loss: 0.28815401904284954\n",
      "Epoch #26 : Step #2900 : NLL Loss: 0.288508123847945\n",
      "Epoch #26 : Step #3000 : NLL Loss: 0.2884528851211071\n",
      "Epoch #26 : Step #3100 : NLL Loss: 0.288537352902274\n",
      "Loss Epoch #26 : 3188 NLL Loss: 0.2896568761715476\n",
      "\n",
      "Epoch #27 : Step #100 : NLL Loss: 0.3196582290530205\n",
      "Epoch #27 : Step #200 : NLL Loss: 0.30993270248174665\n",
      "Epoch #27 : Step #300 : NLL Loss: 0.2938394625981649\n",
      "Epoch #27 : Step #400 : NLL Loss: 0.2922166293114424\n",
      "Epoch #27 : Step #500 : NLL Loss: 0.28852828639745715\n",
      "Epoch #27 : Step #600 : NLL Loss: 0.2836552052696546\n",
      "Epoch #27 : Step #700 : NLL Loss: 0.2882630306908063\n",
      "Epoch #27 : Step #800 : NLL Loss: 0.2883157953247428\n",
      "Epoch #27 : Step #900 : NLL Loss: 0.28792247315247854\n",
      "Epoch #27 : Step #1000 : NLL Loss: 0.28761337158083916\n",
      "Epoch #27 : Step #1100 : NLL Loss: 0.2874212262034416\n",
      "Epoch #27 : Step #1200 : NLL Loss: 0.28827305272221565\n",
      "Epoch #27 : Step #1300 : NLL Loss: 0.29093131927343513\n",
      "Epoch #27 : Step #1400 : NLL Loss: 0.289949453409229\n",
      "Epoch #27 : Step #1500 : NLL Loss: 0.2895012288093567\n",
      "Epoch #27 : Step #1600 : NLL Loss: 0.28915994361042974\n",
      "Epoch #27 : Step #1700 : NLL Loss: 0.2890993497827474\n",
      "Epoch #27 : Step #1800 : NLL Loss: 0.2900181770324707\n",
      "Epoch #27 : Step #1900 : NLL Loss: 0.29048471671970266\n",
      "Epoch #27 : Step #2000 : NLL Loss: 0.29074962159991263\n",
      "Epoch #27 : Step #2100 : NLL Loss: 0.28974336516289484\n",
      "Epoch #27 : Step #2200 : NLL Loss: 0.2880637856505134\n",
      "Epoch #27 : Step #2300 : NLL Loss: 0.2873259538541669\n",
      "Epoch #27 : Step #2400 : NLL Loss: 0.2877848760286967\n",
      "Epoch #27 : Step #2500 : NLL Loss: 0.28828647656440737\n",
      "Epoch #27 : Step #2600 : NLL Loss: 0.2874633094095267\n",
      "Epoch #27 : Step #2700 : NLL Loss: 0.2877938092858703\n",
      "Epoch #27 : Step #2800 : NLL Loss: 0.28800326431436196\n",
      "Epoch #27 : Step #2900 : NLL Loss: 0.28703503891311843\n",
      "Epoch #27 : Step #3000 : NLL Loss: 0.28723266907533007\n",
      "Epoch #27 : Step #3100 : NLL Loss: 0.2872559357458545\n",
      "Loss Epoch #27 : 3188 NLL Loss: 0.287989472954007\n",
      "\n",
      "Epoch #28 : Step #100 : NLL Loss: 0.29873182743787763\n",
      "Epoch #28 : Step #200 : NLL Loss: 0.2820512272417545\n",
      "Epoch #28 : Step #300 : NLL Loss: 0.27960388710101447\n",
      "Epoch #28 : Step #400 : NLL Loss: 0.2807207747548819\n",
      "Epoch #28 : Step #500 : NLL Loss: 0.279289068877697\n",
      "Epoch #28 : Step #600 : NLL Loss: 0.2798525194823742\n",
      "Epoch #28 : Step #700 : NLL Loss: 0.27863667066608155\n",
      "Epoch #28 : Step #800 : NLL Loss: 0.2790400349162519\n",
      "Epoch #28 : Step #900 : NLL Loss: 0.28230194944474435\n",
      "Epoch #28 : Step #1000 : NLL Loss: 0.28222532145678997\n",
      "Epoch #28 : Step #1100 : NLL Loss: 0.2818670359931209\n",
      "Epoch #28 : Step #1200 : NLL Loss: 0.2811700387423237\n",
      "Epoch #28 : Step #1300 : NLL Loss: 0.2806126046066101\n",
      "Epoch #28 : Step #1400 : NLL Loss: 0.28088173973773206\n",
      "Epoch #28 : Step #1500 : NLL Loss: 0.2813368277649085\n",
      "Epoch #28 : Step #1600 : NLL Loss: 0.2807334019709378\n",
      "Epoch #28 : Step #1700 : NLL Loss: 0.2820815177612445\n",
      "Epoch #28 : Step #1800 : NLL Loss: 0.2826838991459873\n",
      "Epoch #28 : Step #1900 : NLL Loss: 0.2826592360280062\n",
      "Epoch #28 : Step #2000 : NLL Loss: 0.2841333162710071\n",
      "Epoch #28 : Step #2100 : NLL Loss: 0.28474611178040504\n",
      "Epoch #28 : Step #2200 : NLL Loss: 0.2852360674129291\n",
      "Epoch #28 : Step #2300 : NLL Loss: 0.2862044488930184\n",
      "Epoch #28 : Step #2400 : NLL Loss: 0.28711898628001414\n",
      "Epoch #28 : Step #2500 : NLL Loss: 0.28620289629101753\n",
      "Epoch #28 : Step #2600 : NLL Loss: 0.28653883305306616\n",
      "Epoch #28 : Step #2700 : NLL Loss: 0.28670875959374287\n",
      "Epoch #28 : Step #2800 : NLL Loss: 0.2865858371502587\n",
      "Epoch #28 : Step #2900 : NLL Loss: 0.28631638951856514\n",
      "Epoch #28 : Step #3000 : NLL Loss: 0.2871509242604176\n",
      "Epoch #28 : Step #3100 : NLL Loss: 0.2868845756736494\n",
      "Loss Epoch #28 : 3188 NLL Loss: 0.2865426047673563\n",
      "\n",
      "Epoch #29 : Step #100 : NLL Loss: 0.2793606975674629\n",
      "Epoch #29 : Step #200 : NLL Loss: 0.26373241618275645\n",
      "Epoch #29 : Step #300 : NLL Loss: 0.2799252504110336\n",
      "Epoch #29 : Step #400 : NLL Loss: 0.2742839717119932\n",
      "Epoch #29 : Step #500 : NLL Loss: 0.27871042156219483\n",
      "Epoch #29 : Step #600 : NLL Loss: 0.281818827688694\n",
      "Epoch #29 : Step #700 : NLL Loss: 0.2827128492934363\n",
      "Epoch #29 : Step #800 : NLL Loss: 0.28177398692816497\n",
      "Epoch #29 : Step #900 : NLL Loss: 0.27920884092648823\n",
      "Epoch #29 : Step #1000 : NLL Loss: 0.2809912480711937\n",
      "Epoch #29 : Step #1100 : NLL Loss: 0.28311447484926744\n",
      "Epoch #29 : Step #1200 : NLL Loss: 0.28421621801952524\n",
      "Epoch #29 : Step #1300 : NLL Loss: 0.28436818613455844\n",
      "Epoch #29 : Step #1400 : NLL Loss: 0.28401158596788134\n",
      "Epoch #29 : Step #1500 : NLL Loss: 0.28314720368385315\n",
      "Epoch #29 : Step #1600 : NLL Loss: 0.2824872355163097\n",
      "Epoch #29 : Step #1700 : NLL Loss: 0.28432455019039266\n",
      "Epoch #29 : Step #1800 : NLL Loss: 0.2836495729949739\n",
      "Epoch #29 : Step #1900 : NLL Loss: 0.2837368381337116\n",
      "Epoch #29 : Step #2000 : NLL Loss: 0.2849571179449558\n",
      "Epoch #29 : Step #2100 : NLL Loss: 0.2846998687585195\n",
      "Epoch #29 : Step #2200 : NLL Loss: 0.28527470287951556\n",
      "Epoch #29 : Step #2300 : NLL Loss: 0.2837396128281303\n",
      "Epoch #29 : Step #2400 : NLL Loss: 0.28393870261808235\n",
      "Epoch #29 : Step #2500 : NLL Loss: 0.285295672929287\n",
      "Epoch #29 : Step #2600 : NLL Loss: 0.2861232072114944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #29 : Step #2700 : NLL Loss: 0.28504962884717516\n",
      "Epoch #29 : Step #2800 : NLL Loss: 0.28456944309175014\n",
      "Epoch #29 : Step #2900 : NLL Loss: 0.2850402404213774\n",
      "Epoch #29 : Step #3000 : NLL Loss: 0.28543336428205174\n",
      "Epoch #29 : Step #3100 : NLL Loss: 0.28456861234480335\n",
      "Loss Epoch #29 : 3188 NLL Loss: 0.285109181756357\n",
      "\n",
      "Epoch #30 : Step #100 : NLL Loss: 0.2791083097457886\n",
      "Epoch #30 : Step #200 : NLL Loss: 0.28846052184700965\n",
      "Epoch #30 : Step #300 : NLL Loss: 0.28265669653813047\n",
      "Epoch #30 : Step #400 : NLL Loss: 0.2842049807310104\n",
      "Epoch #30 : Step #500 : NLL Loss: 0.27940057188272477\n",
      "Epoch #30 : Step #600 : NLL Loss: 0.27713426560163495\n",
      "Epoch #30 : Step #700 : NLL Loss: 0.28014902723687035\n",
      "Epoch #30 : Step #800 : NLL Loss: 0.27863964293152094\n",
      "Epoch #30 : Step #900 : NLL Loss: 0.28056484921111\n",
      "Epoch #30 : Step #1000 : NLL Loss: 0.27955946877598764\n",
      "Epoch #30 : Step #1100 : NLL Loss: 0.27898378960110926\n",
      "Epoch #30 : Step #1200 : NLL Loss: 0.2767645520468553\n",
      "Epoch #30 : Step #1300 : NLL Loss: 0.2794339703367307\n",
      "Epoch #30 : Step #1400 : NLL Loss: 0.2828061423982893\n",
      "Epoch #30 : Step #1500 : NLL Loss: 0.2844215486844381\n",
      "Epoch #30 : Step #1600 : NLL Loss: 0.28421318110078575\n",
      "Epoch #30 : Step #1700 : NLL Loss: 0.2847745631372227\n",
      "Epoch #30 : Step #1800 : NLL Loss: 0.28604057633214525\n",
      "Epoch #30 : Step #1900 : NLL Loss: 0.2863067223680647\n",
      "Epoch #30 : Step #2000 : NLL Loss: 0.2854040557295084\n",
      "Epoch #30 : Step #2100 : NLL Loss: 0.28697027833688826\n",
      "Epoch #30 : Step #2200 : NLL Loss: 0.2868908591162075\n",
      "Epoch #30 : Step #2300 : NLL Loss: 0.2865854821904846\n",
      "Epoch #30 : Step #2400 : NLL Loss: 0.2856707721265654\n",
      "Epoch #30 : Step #2500 : NLL Loss: 0.28418814517855645\n",
      "Epoch #30 : Step #2600 : NLL Loss: 0.28445233526711283\n",
      "Epoch #30 : Step #2700 : NLL Loss: 0.2842723778276532\n",
      "Epoch #30 : Step #2800 : NLL Loss: 0.28372644224869353\n",
      "Epoch #30 : Step #2900 : NLL Loss: 0.28338859018066836\n",
      "Epoch #30 : Step #3000 : NLL Loss: 0.2842610663721959\n",
      "Epoch #30 : Step #3100 : NLL Loss: 0.28432167207521775\n",
      "Loss Epoch #30 : 3188 NLL Loss: 0.2837795116512135\n",
      "\n",
      "Epoch #31 : Step #100 : NLL Loss: 0.28758582651615144\n",
      "Epoch #31 : Step #200 : NLL Loss: 0.2853911231458187\n",
      "Epoch #31 : Step #300 : NLL Loss: 0.27963712900876997\n",
      "Epoch #31 : Step #400 : NLL Loss: 0.2818662917613983\n",
      "Epoch #31 : Step #500 : NLL Loss: 0.28458044475317\n",
      "Epoch #31 : Step #600 : NLL Loss: 0.28440310498078664\n",
      "Epoch #31 : Step #700 : NLL Loss: 0.28360152525561194\n",
      "Epoch #31 : Step #800 : NLL Loss: 0.2855485262721777\n",
      "Epoch #31 : Step #900 : NLL Loss: 0.28417548328638076\n",
      "Epoch #31 : Step #1000 : NLL Loss: 0.2852200201153755\n",
      "Epoch #31 : Step #1100 : NLL Loss: 0.2860698332569816\n",
      "Epoch #31 : Step #1200 : NLL Loss: 0.28573951341211795\n",
      "Epoch #31 : Step #1300 : NLL Loss: 0.2857633524445387\n",
      "Epoch #31 : Step #1400 : NLL Loss: 0.28348998071891923\n",
      "Epoch #31 : Step #1500 : NLL Loss: 0.281796132226785\n",
      "Epoch #31 : Step #1600 : NLL Loss: 0.2811386785469949\n",
      "Epoch #31 : Step #1700 : NLL Loss: 0.2812457763272173\n",
      "Epoch #31 : Step #1800 : NLL Loss: 0.2809532737235228\n",
      "Epoch #31 : Step #1900 : NLL Loss: 0.28057636822524823\n",
      "Epoch #31 : Step #2000 : NLL Loss: 0.28076017639040945\n",
      "Epoch #31 : Step #2100 : NLL Loss: 0.2813912890354792\n",
      "Epoch #31 : Step #2200 : NLL Loss: 0.2809529460018331\n",
      "Epoch #31 : Step #2300 : NLL Loss: 0.28230191729638887\n",
      "Epoch #31 : Step #2400 : NLL Loss: 0.28232502919932206\n",
      "Epoch #31 : Step #2500 : NLL Loss: 0.28229994049072266\n",
      "Epoch #31 : Step #2600 : NLL Loss: 0.28354760167690424\n",
      "Epoch #31 : Step #2700 : NLL Loss: 0.28218636666183117\n",
      "Epoch #31 : Step #2800 : NLL Loss: 0.28057145049529414\n",
      "Epoch #31 : Step #2900 : NLL Loss: 0.2810829650944677\n",
      "Epoch #31 : Step #3000 : NLL Loss: 0.28132658745845157\n",
      "Epoch #31 : Step #3100 : NLL Loss: 0.28172747609115417\n",
      "Loss Epoch #31 : 3188 NLL Loss: 0.28240694755330736\n",
      "\n",
      "Epoch #32 : Step #100 : NLL Loss: 0.28001668214797976\n",
      "Epoch #32 : Step #200 : NLL Loss: 0.2814593179523945\n",
      "Epoch #32 : Step #300 : NLL Loss: 0.2717594797412554\n",
      "Epoch #32 : Step #400 : NLL Loss: 0.2765254035592079\n",
      "Epoch #32 : Step #500 : NLL Loss: 0.2824645500779152\n",
      "Epoch #32 : Step #600 : NLL Loss: 0.2808328804373741\n",
      "Epoch #32 : Step #700 : NLL Loss: 0.2815276265144348\n",
      "Epoch #32 : Step #800 : NLL Loss: 0.28153149675577877\n",
      "Epoch #32 : Step #900 : NLL Loss: 0.28241573764218225\n",
      "Epoch #32 : Step #1000 : NLL Loss: 0.28073831874132155\n",
      "Epoch #32 : Step #1100 : NLL Loss: 0.283663424632766\n",
      "Epoch #32 : Step #1200 : NLL Loss: 0.28492343706389267\n",
      "Epoch #32 : Step #1300 : NLL Loss: 0.2830344505722706\n",
      "Epoch #32 : Step #1400 : NLL Loss: 0.2816325856106622\n",
      "Epoch #32 : Step #1500 : NLL Loss: 0.2824511378010114\n",
      "Epoch #32 : Step #1600 : NLL Loss: 0.28120924189686775\n",
      "Epoch #32 : Step #1700 : NLL Loss: 0.2814890592764406\n",
      "Epoch #32 : Step #1800 : NLL Loss: 0.2799667126023107\n",
      "Epoch #32 : Step #1900 : NLL Loss: 0.28179641007592804\n",
      "Epoch #32 : Step #2000 : NLL Loss: 0.2818164535835385\n",
      "Epoch #32 : Step #2100 : NLL Loss: 0.28205914529306547\n",
      "Epoch #32 : Step #2200 : NLL Loss: 0.2818181772055951\n",
      "Epoch #32 : Step #2300 : NLL Loss: 0.28178766100950864\n",
      "Epoch #32 : Step #2400 : NLL Loss: 0.2812012556133171\n",
      "Epoch #32 : Step #2500 : NLL Loss: 0.28160436467528344\n",
      "Epoch #32 : Step #2600 : NLL Loss: 0.2821541087730573\n",
      "Epoch #32 : Step #2700 : NLL Loss: 0.2827934790485435\n",
      "Epoch #32 : Step #2800 : NLL Loss: 0.2833682822382876\n",
      "Epoch #32 : Step #2900 : NLL Loss: 0.28164770669464406\n",
      "Epoch #32 : Step #3000 : NLL Loss: 0.281296297048529\n",
      "Epoch #32 : Step #3100 : NLL Loss: 0.2811442609996565\n",
      "Loss Epoch #32 : 3188 NLL Loss: 0.2811870208732232\n",
      "\n",
      "Epoch #33 : Step #100 : NLL Loss: 0.28933713644742964\n",
      "Epoch #33 : Step #200 : NLL Loss: 0.26817213132977485\n",
      "Epoch #33 : Step #300 : NLL Loss: 0.26745047767957053\n",
      "Epoch #33 : Step #400 : NLL Loss: 0.26165871471166613\n",
      "Epoch #33 : Step #500 : NLL Loss: 0.26514334028959274\n",
      "Epoch #33 : Step #600 : NLL Loss: 0.2670742444694042\n",
      "Epoch #33 : Step #700 : NLL Loss: 0.2694397728357996\n",
      "Epoch #33 : Step #800 : NLL Loss: 0.2707787994667888\n",
      "Epoch #33 : Step #900 : NLL Loss: 0.2718387727936109\n",
      "Epoch #33 : Step #1000 : NLL Loss: 0.2736671480238438\n",
      "Epoch #33 : Step #1100 : NLL Loss: 0.27693123757839205\n",
      "Epoch #33 : Step #1200 : NLL Loss: 0.2770393942296505\n",
      "Epoch #33 : Step #1300 : NLL Loss: 0.2773777518593348\n",
      "Epoch #33 : Step #1400 : NLL Loss: 0.27843860472951615\n",
      "Epoch #33 : Step #1500 : NLL Loss: 0.28016497401396434\n",
      "Epoch #33 : Step #1600 : NLL Loss: 0.2791561380028725\n",
      "Epoch #33 : Step #1700 : NLL Loss: 0.2789650181461783\n",
      "Epoch #33 : Step #1800 : NLL Loss: 0.2794164167179002\n",
      "Epoch #33 : Step #1900 : NLL Loss: 0.2794407344021295\n",
      "Epoch #33 : Step #2000 : NLL Loss: 0.2793884388208389\n",
      "Epoch #33 : Step #2100 : NLL Loss: 0.27995826580694744\n",
      "Epoch #33 : Step #2200 : NLL Loss: 0.2795585383881222\n",
      "Epoch #33 : Step #2300 : NLL Loss: 0.28024729555067807\n",
      "Epoch #33 : Step #2400 : NLL Loss: 0.28021367837985356\n",
      "Epoch #33 : Step #2500 : NLL Loss: 0.27962047744989393\n",
      "Epoch #33 : Step #2600 : NLL Loss: 0.2800075175555853\n",
      "Epoch #33 : Step #2700 : NLL Loss: 0.279163897479022\n",
      "Epoch #33 : Step #2800 : NLL Loss: 0.2783287474619491\n",
      "Epoch #33 : Step #2900 : NLL Loss: 0.2786416927391085\n",
      "Epoch #33 : Step #3000 : NLL Loss: 0.2783921543757121\n",
      "Epoch #33 : Step #3100 : NLL Loss: 0.2794590065267778\n",
      "Loss Epoch #33 : 3188 NLL Loss: 0.2802001093438309\n",
      "\n",
      "Epoch #34 : Step #100 : NLL Loss: 0.2720119988918304\n",
      "Epoch #34 : Step #200 : NLL Loss: 0.2814053499698639\n",
      "Epoch #34 : Step #300 : NLL Loss: 0.281115235388279\n",
      "Epoch #34 : Step #400 : NLL Loss: 0.28265409827232363\n",
      "Epoch #34 : Step #500 : NLL Loss: 0.2799789111018181\n",
      "Epoch #34 : Step #600 : NLL Loss: 0.27939665630459787\n",
      "Epoch #34 : Step #700 : NLL Loss: 0.2783521370802607\n",
      "Epoch #34 : Step #800 : NLL Loss: 0.2761489960178733\n",
      "Epoch #34 : Step #900 : NLL Loss: 0.27547644452916253\n",
      "Epoch #34 : Step #1000 : NLL Loss: 0.27636178520321847\n",
      "Epoch #34 : Step #1100 : NLL Loss: 0.2773137771541422\n",
      "Epoch #34 : Step #1200 : NLL Loss: 0.2782690613468488\n",
      "Epoch #34 : Step #1300 : NLL Loss: 0.27789433538913727\n",
      "Epoch #34 : Step #1400 : NLL Loss: 0.27787404577646935\n",
      "Epoch #34 : Step #1500 : NLL Loss: 0.27845982752243675\n",
      "Epoch #34 : Step #1600 : NLL Loss: 0.27906723208725454\n",
      "Epoch #34 : Step #1700 : NLL Loss: 0.27856009900569917\n",
      "Epoch #34 : Step #1800 : NLL Loss: 0.27683302375177543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #34 : Step #1900 : NLL Loss: 0.2757549960440711\n",
      "Epoch #34 : Step #2000 : NLL Loss: 0.27666096641868354\n",
      "Epoch #34 : Step #2100 : NLL Loss: 0.27683255931451206\n",
      "Epoch #34 : Step #2200 : NLL Loss: 0.2783753036030314\n",
      "Epoch #34 : Step #2300 : NLL Loss: 0.27797556066642637\n",
      "Epoch #34 : Step #2400 : NLL Loss: 0.2777432103889684\n",
      "Epoch #34 : Step #2500 : NLL Loss: 0.2774116170704365\n",
      "Epoch #34 : Step #2600 : NLL Loss: 0.2785684474099141\n",
      "Epoch #34 : Step #2700 : NLL Loss: 0.27886282806595164\n",
      "Epoch #34 : Step #2800 : NLL Loss: 0.27872266894472497\n",
      "Epoch #34 : Step #2900 : NLL Loss: 0.278282491569889\n",
      "Epoch #34 : Step #3000 : NLL Loss: 0.27860481462379294\n",
      "Epoch #34 : Step #3100 : NLL Loss: 0.2789381901246886\n",
      "Loss Epoch #34 : 3188 NLL Loss: 0.27904916141027936\n",
      "\n",
      "Epoch #35 : Step #100 : NLL Loss: 0.27583352714776993\n",
      "Epoch #35 : Step #200 : NLL Loss: 0.2749754309654236\n",
      "Epoch #35 : Step #300 : NLL Loss: 0.2793347628911336\n",
      "Epoch #35 : Step #400 : NLL Loss: 0.27652837850153444\n",
      "Epoch #35 : Step #500 : NLL Loss: 0.2755621547698975\n",
      "Epoch #35 : Step #600 : NLL Loss: 0.2748154346644878\n",
      "Epoch #35 : Step #700 : NLL Loss: 0.27478656977415084\n",
      "Epoch #35 : Step #800 : NLL Loss: 0.276060557551682\n",
      "Epoch #35 : Step #900 : NLL Loss: 0.27891660581032435\n",
      "Epoch #35 : Step #1000 : NLL Loss: 0.28037702348828314\n",
      "Epoch #35 : Step #1100 : NLL Loss: 0.2785635498166084\n",
      "Epoch #35 : Step #1200 : NLL Loss: 0.2793995315829913\n",
      "Epoch #35 : Step #1300 : NLL Loss: 0.2808772503183438\n",
      "Epoch #35 : Step #1400 : NLL Loss: 0.2813823203955378\n",
      "Epoch #35 : Step #1500 : NLL Loss: 0.2830164386232694\n",
      "Epoch #35 : Step #1600 : NLL Loss: 0.2825005920231342\n",
      "Epoch #35 : Step #1700 : NLL Loss: 0.28199817561051427\n",
      "Epoch #35 : Step #1800 : NLL Loss: 0.2825814307232698\n",
      "Epoch #35 : Step #1900 : NLL Loss: 0.2824499128523626\n",
      "Epoch #35 : Step #2000 : NLL Loss: 0.28136522288620475\n",
      "Epoch #35 : Step #2100 : NLL Loss: 0.281490551900296\n",
      "Epoch #35 : Step #2200 : NLL Loss: 0.28303280593319374\n",
      "Epoch #35 : Step #2300 : NLL Loss: 0.28230367470046747\n",
      "Epoch #35 : Step #2400 : NLL Loss: 0.2818620336676637\n",
      "Epoch #35 : Step #2500 : NLL Loss: 0.2808248371124268\n",
      "Epoch #35 : Step #2600 : NLL Loss: 0.2801827467290255\n",
      "Epoch #35 : Step #2700 : NLL Loss: 0.28012751592530144\n",
      "Epoch #35 : Step #2800 : NLL Loss: 0.2793488836394889\n",
      "Epoch #35 : Step #2900 : NLL Loss: 0.27938070229415235\n",
      "Epoch #35 : Step #3000 : NLL Loss: 0.2788660330474377\n",
      "Epoch #35 : Step #3100 : NLL Loss: 0.2785511766518316\n",
      "Loss Epoch #35 : 3188 NLL Loss: 0.278390918632822\n",
      "\n",
      "Epoch #36 : Step #100 : NLL Loss: 0.2862488865852356\n",
      "Epoch #36 : Step #200 : NLL Loss: 0.27117702141404154\n",
      "Epoch #36 : Step #300 : NLL Loss: 0.2778129535913467\n",
      "Epoch #36 : Step #400 : NLL Loss: 0.2810965064167976\n",
      "Epoch #36 : Step #500 : NLL Loss: 0.2789103021025658\n",
      "Epoch #36 : Step #600 : NLL Loss: 0.27566436658302945\n",
      "Epoch #36 : Step #700 : NLL Loss: 0.2732604395065989\n",
      "Epoch #36 : Step #800 : NLL Loss: 0.2711796010285616\n",
      "Epoch #36 : Step #900 : NLL Loss: 0.27308972434865103\n",
      "Epoch #36 : Step #1000 : NLL Loss: 0.27310195672512055\n",
      "Epoch #36 : Step #1100 : NLL Loss: 0.27447754380377853\n",
      "Epoch #36 : Step #1200 : NLL Loss: 0.2739635477711757\n",
      "Epoch #36 : Step #1300 : NLL Loss: 0.2756460686142628\n",
      "Epoch #36 : Step #1400 : NLL Loss: 0.27521080491798267\n",
      "Epoch #36 : Step #1500 : NLL Loss: 0.27649187729756036\n",
      "Epoch #36 : Step #1600 : NLL Loss: 0.2766876331530511\n",
      "Epoch #36 : Step #1700 : NLL Loss: 0.27573892819530826\n",
      "Epoch #36 : Step #1800 : NLL Loss: 0.275909667627679\n",
      "Epoch #36 : Step #1900 : NLL Loss: 0.2771203653906521\n",
      "Epoch #36 : Step #2000 : NLL Loss: 0.27896610997617244\n",
      "Epoch #36 : Step #2100 : NLL Loss: 0.2797575450511206\n",
      "Epoch #36 : Step #2200 : NLL Loss: 0.2800736583362926\n",
      "Epoch #36 : Step #2300 : NLL Loss: 0.2786857707215392\n",
      "Epoch #36 : Step #2400 : NLL Loss: 0.27890829016764956\n",
      "Epoch #36 : Step #2500 : NLL Loss: 0.27835920832157135\n",
      "Epoch #36 : Step #2600 : NLL Loss: 0.2786033449952419\n",
      "Epoch #36 : Step #2700 : NLL Loss: 0.2786231950146181\n",
      "Epoch #36 : Step #2800 : NLL Loss: 0.27798205567257744\n",
      "Epoch #36 : Step #2900 : NLL Loss: 0.2774579085358258\n",
      "Epoch #36 : Step #3000 : NLL Loss: 0.2772728118896484\n",
      "Epoch #36 : Step #3100 : NLL Loss: 0.2771047115710474\n",
      "Loss Epoch #36 : 3188 NLL Loss: 0.2771638851037887\n",
      "\n",
      "Epoch #37 : Step #100 : NLL Loss: 0.27413616836071014\n",
      "Epoch #37 : Step #200 : NLL Loss: 0.26877849400043485\n",
      "Epoch #37 : Step #300 : NLL Loss: 0.2739261065920194\n",
      "Epoch #37 : Step #400 : NLL Loss: 0.268897395581007\n",
      "Epoch #37 : Step #500 : NLL Loss: 0.27616755485534666\n",
      "Epoch #37 : Step #600 : NLL Loss: 0.2734625568985939\n",
      "Epoch #37 : Step #700 : NLL Loss: 0.27422723267759597\n",
      "Epoch #37 : Step #800 : NLL Loss: 0.2759398813918233\n",
      "Epoch #37 : Step #900 : NLL Loss: 0.2773244469364484\n",
      "Epoch #37 : Step #1000 : NLL Loss: 0.2774523192048073\n",
      "Epoch #37 : Step #1100 : NLL Loss: 0.27632634196769107\n",
      "Epoch #37 : Step #1200 : NLL Loss: 0.27674094576388597\n",
      "Epoch #37 : Step #1300 : NLL Loss: 0.2745916087466937\n",
      "Epoch #37 : Step #1400 : NLL Loss: 0.2748794814412083\n",
      "Epoch #37 : Step #1500 : NLL Loss: 0.27586309821407\n",
      "Epoch #37 : Step #1600 : NLL Loss: 0.2771398815046996\n",
      "Epoch #37 : Step #1700 : NLL Loss: 0.2778840383098406\n",
      "Epoch #37 : Step #1800 : NLL Loss: 0.27749609204630055\n",
      "Epoch #37 : Step #1900 : NLL Loss: 0.2770615133407869\n",
      "Epoch #37 : Step #2000 : NLL Loss: 0.27684188755601646\n",
      "Epoch #37 : Step #2100 : NLL Loss: 0.27678900327710876\n",
      "Epoch #37 : Step #2200 : NLL Loss: 0.2772204662249847\n",
      "Epoch #37 : Step #2300 : NLL Loss: 0.2768784935772419\n",
      "Epoch #37 : Step #2400 : NLL Loss: 0.2770829773756365\n",
      "Epoch #37 : Step #2500 : NLL Loss: 0.2772169119775295\n",
      "Epoch #37 : Step #2600 : NLL Loss: 0.27815599091351034\n",
      "Epoch #37 : Step #2700 : NLL Loss: 0.2776542657668944\n",
      "Epoch #37 : Step #2800 : NLL Loss: 0.2769740956755621\n",
      "Epoch #37 : Step #2900 : NLL Loss: 0.27747217126447576\n",
      "Epoch #37 : Step #3000 : NLL Loss: 0.2776128779798746\n",
      "Epoch #37 : Step #3100 : NLL Loss: 0.2771092700044955\n",
      "Loss Epoch #37 : 3188 NLL Loss: 0.2762366279800758\n",
      "\n",
      "Epoch #38 : Step #100 : NLL Loss: 0.26758052289485934\n",
      "Epoch #38 : Step #200 : NLL Loss: 0.27244721293449403\n",
      "Epoch #38 : Step #300 : NLL Loss: 0.27175793836514156\n",
      "Epoch #38 : Step #400 : NLL Loss: 0.2737965216487646\n",
      "Epoch #38 : Step #500 : NLL Loss: 0.2832023872733116\n",
      "Epoch #38 : Step #600 : NLL Loss: 0.2777841825286547\n",
      "Epoch #38 : Step #700 : NLL Loss: 0.28390600404569083\n",
      "Epoch #38 : Step #800 : NLL Loss: 0.28271129209548235\n",
      "Epoch #38 : Step #900 : NLL Loss: 0.27993253658215206\n",
      "Epoch #38 : Step #1000 : NLL Loss: 0.2793577144443989\n",
      "Epoch #38 : Step #1100 : NLL Loss: 0.2754585772752762\n",
      "Epoch #38 : Step #1200 : NLL Loss: 0.27402670341233415\n",
      "Epoch #38 : Step #1300 : NLL Loss: 0.27611029397982817\n",
      "Epoch #38 : Step #1400 : NLL Loss: 0.2735605365037918\n",
      "Epoch #38 : Step #1500 : NLL Loss: 0.27349367556969323\n",
      "Epoch #38 : Step #1600 : NLL Loss: 0.27358784947544335\n",
      "Epoch #38 : Step #1700 : NLL Loss: 0.2737711239562315\n",
      "Epoch #38 : Step #1800 : NLL Loss: 0.273919662386179\n",
      "Epoch #38 : Step #1900 : NLL Loss: 0.27413156040404973\n",
      "Epoch #38 : Step #2000 : NLL Loss: 0.27478221960365773\n",
      "Epoch #38 : Step #2100 : NLL Loss: 0.2738672949302764\n",
      "Epoch #38 : Step #2200 : NLL Loss: 0.27347668412056836\n",
      "Epoch #38 : Step #2300 : NLL Loss: 0.27322991231213445\n",
      "Epoch #38 : Step #2400 : NLL Loss: 0.27357454931984343\n",
      "Epoch #38 : Step #2500 : NLL Loss: 0.27298454204797745\n",
      "Epoch #38 : Step #2600 : NLL Loss: 0.27286336550345786\n",
      "Epoch #38 : Step #2700 : NLL Loss: 0.2733801606849388\n",
      "Epoch #38 : Step #2800 : NLL Loss: 0.27391620661531174\n",
      "Epoch #38 : Step #2900 : NLL Loss: 0.2738788189816064\n",
      "Epoch #38 : Step #3000 : NLL Loss: 0.27379341018696624\n",
      "Epoch #38 : Step #3100 : NLL Loss: 0.27434846217113157\n",
      "Loss Epoch #38 : 3188 NLL Loss: 0.2752442385959281\n",
      "\n",
      "Epoch #39 : Step #100 : NLL Loss: 0.255656298995018\n",
      "Epoch #39 : Step #200 : NLL Loss: 0.2595444117486477\n",
      "Epoch #39 : Step #300 : NLL Loss: 0.26966739863157274\n",
      "Epoch #39 : Step #400 : NLL Loss: 0.27313059628009795\n",
      "Epoch #39 : Step #500 : NLL Loss: 0.27607028353214264\n",
      "Epoch #39 : Step #600 : NLL Loss: 0.2768087642391523\n",
      "Epoch #39 : Step #700 : NLL Loss: 0.2780748048850468\n",
      "Epoch #39 : Step #800 : NLL Loss: 0.27839541625231506\n",
      "Epoch #39 : Step #900 : NLL Loss: 0.2788127295176188\n",
      "Epoch #39 : Step #1000 : NLL Loss: 0.2772588058412075\n",
      "Epoch #39 : Step #1100 : NLL Loss: 0.2769859262759035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #39 : Step #1200 : NLL Loss: 0.2760102513929208\n",
      "Epoch #39 : Step #1300 : NLL Loss: 0.2764447035010044\n",
      "Epoch #39 : Step #1400 : NLL Loss: 0.275773047719683\n",
      "Epoch #39 : Step #1500 : NLL Loss: 0.274072335600853\n",
      "Epoch #39 : Step #1600 : NLL Loss: 0.27500954311341047\n",
      "Epoch #39 : Step #1700 : NLL Loss: 0.2744770018493428\n",
      "Epoch #39 : Step #1800 : NLL Loss: 0.2746285655928983\n",
      "Epoch #39 : Step #1900 : NLL Loss: 0.27400897742886293\n",
      "Epoch #39 : Step #2000 : NLL Loss: 0.2734806661605835\n",
      "Epoch #39 : Step #2100 : NLL Loss: 0.2718750817860876\n",
      "Epoch #39 : Step #2200 : NLL Loss: 0.27161331950263545\n",
      "Epoch #39 : Step #2300 : NLL Loss: 0.27240407183118487\n",
      "Epoch #39 : Step #2400 : NLL Loss: 0.2730951209863027\n",
      "Epoch #39 : Step #2500 : NLL Loss: 0.2737633843660355\n",
      "Epoch #39 : Step #2600 : NLL Loss: 0.2743750479358893\n",
      "Epoch #39 : Step #2700 : NLL Loss: 0.27489003870222306\n",
      "Epoch #39 : Step #2800 : NLL Loss: 0.27353152263377395\n",
      "Epoch #39 : Step #2900 : NLL Loss: 0.2729113427318376\n",
      "Epoch #39 : Step #3000 : NLL Loss: 0.27364303688208264\n",
      "Epoch #39 : Step #3100 : NLL Loss: 0.27428955680901007\n",
      "Loss Epoch #39 : 3188 NLL Loss: 0.27451030042494556\n",
      "\n",
      "Epoch #40 : Step #100 : NLL Loss: 0.26597208857536314\n",
      "Epoch #40 : Step #200 : NLL Loss: 0.2743496887385845\n",
      "Epoch #40 : Step #300 : NLL Loss: 0.27062382767597837\n",
      "Epoch #40 : Step #400 : NLL Loss: 0.26339101865887643\n",
      "Epoch #40 : Step #500 : NLL Loss: 0.26457040494680406\n",
      "Epoch #40 : Step #600 : NLL Loss: 0.26844683224956195\n",
      "Epoch #40 : Step #700 : NLL Loss: 0.26472685017756054\n",
      "Epoch #40 : Step #800 : NLL Loss: 0.26689061515033247\n",
      "Epoch #40 : Step #900 : NLL Loss: 0.26688962380091347\n",
      "Epoch #40 : Step #1000 : NLL Loss: 0.268281639367342\n",
      "Epoch #40 : Step #1100 : NLL Loss: 0.269618384485895\n",
      "Epoch #40 : Step #1200 : NLL Loss: 0.2699048371613026\n",
      "Epoch #40 : Step #1300 : NLL Loss: 0.270169683098793\n",
      "Epoch #40 : Step #1400 : NLL Loss: 0.27176653847098353\n",
      "Epoch #40 : Step #1500 : NLL Loss: 0.2728247493902842\n",
      "Epoch #40 : Step #1600 : NLL Loss: 0.2735613723471761\n",
      "Epoch #40 : Step #1700 : NLL Loss: 0.2753908054092351\n",
      "Epoch #40 : Step #1800 : NLL Loss: 0.2740709518227312\n",
      "Epoch #40 : Step #1900 : NLL Loss: 0.2732918323341169\n",
      "Epoch #40 : Step #2000 : NLL Loss: 0.2732542100250721\n",
      "Epoch #40 : Step #2100 : NLL Loss: 0.2748463371254149\n",
      "Epoch #40 : Step #2200 : NLL Loss: 0.27393825455145404\n",
      "Epoch #40 : Step #2300 : NLL Loss: 0.27365392990734266\n",
      "Epoch #40 : Step #2400 : NLL Loss: 0.2726802401492993\n",
      "Epoch #40 : Step #2500 : NLL Loss: 0.2725179682731628\n",
      "Epoch #40 : Step #2600 : NLL Loss: 0.27211881426664497\n",
      "Epoch #40 : Step #2700 : NLL Loss: 0.2717464534000114\n",
      "Epoch #40 : Step #2800 : NLL Loss: 0.27237969846597737\n",
      "Epoch #40 : Step #2900 : NLL Loss: 0.2729880649879061\n",
      "Epoch #40 : Step #3000 : NLL Loss: 0.27446420753995576\n",
      "Epoch #40 : Step #3100 : NLL Loss: 0.2740851953241133\n",
      "Loss Epoch #40 : 3188 NLL Loss: 0.27369100764075965\n",
      "\n",
      "Epoch #41 : Step #100 : NLL Loss: 0.2679293632507324\n",
      "Epoch #41 : Step #200 : NLL Loss: 0.26997251957654955\n",
      "Epoch #41 : Step #300 : NLL Loss: 0.26863053560256955\n",
      "Epoch #41 : Step #400 : NLL Loss: 0.27282620295882226\n",
      "Epoch #41 : Step #500 : NLL Loss: 0.27378667998313905\n",
      "Epoch #41 : Step #600 : NLL Loss: 0.2728939079741637\n",
      "Epoch #41 : Step #700 : NLL Loss: 0.2766605272889137\n",
      "Epoch #41 : Step #800 : NLL Loss: 0.2812122378870845\n",
      "Epoch #41 : Step #900 : NLL Loss: 0.28017216940720874\n",
      "Epoch #41 : Step #1000 : NLL Loss: 0.28009617680311205\n",
      "Epoch #41 : Step #1100 : NLL Loss: 0.2775594888221134\n",
      "Epoch #41 : Step #1200 : NLL Loss: 0.2776516999304295\n",
      "Epoch #41 : Step #1300 : NLL Loss: 0.2762940354072131\n",
      "Epoch #41 : Step #1400 : NLL Loss: 0.27795540360467774\n",
      "Epoch #41 : Step #1500 : NLL Loss: 0.27823445343971254\n",
      "Epoch #41 : Step #1600 : NLL Loss: 0.2773295932821929\n",
      "Epoch #41 : Step #1700 : NLL Loss: 0.27854202847270404\n",
      "Epoch #41 : Step #1800 : NLL Loss: 0.27817453304926554\n",
      "Epoch #41 : Step #1900 : NLL Loss: 0.2779167019536621\n",
      "Epoch #41 : Step #2000 : NLL Loss: 0.2766939620822668\n",
      "Epoch #41 : Step #2100 : NLL Loss: 0.27463912213132496\n",
      "Epoch #41 : Step #2200 : NLL Loss: 0.27480967789888383\n",
      "Epoch #41 : Step #2300 : NLL Loss: 0.2745307646886162\n",
      "Epoch #41 : Step #2400 : NLL Loss: 0.27374428973843656\n",
      "Epoch #41 : Step #2500 : NLL Loss: 0.27351084932088854\n",
      "Epoch #41 : Step #2600 : NLL Loss: 0.27231321635154576\n",
      "Epoch #41 : Step #2700 : NLL Loss: 0.27304861611790127\n",
      "Epoch #41 : Step #2800 : NLL Loss: 0.27185992791184355\n",
      "Epoch #41 : Step #2900 : NLL Loss: 0.2727723305184266\n",
      "Epoch #41 : Step #3000 : NLL Loss: 0.2729818262954553\n",
      "Epoch #41 : Step #3100 : NLL Loss: 0.27281022121829374\n",
      "Loss Epoch #41 : 3188 NLL Loss: 0.2729637214687268\n",
      "\n",
      "Epoch #42 : Step #100 : NLL Loss: 0.25030321419239043\n",
      "Epoch #42 : Step #200 : NLL Loss: 0.2633109533786774\n",
      "Epoch #42 : Step #300 : NLL Loss: 0.26596247345209123\n",
      "Epoch #42 : Step #400 : NLL Loss: 0.2675311970710754\n",
      "Epoch #42 : Step #500 : NLL Loss: 0.2656630616784096\n",
      "Epoch #42 : Step #600 : NLL Loss: 0.2669832542041938\n",
      "Epoch #42 : Step #700 : NLL Loss: 0.2670013159939221\n",
      "Epoch #42 : Step #800 : NLL Loss: 0.2664332985132933\n",
      "Epoch #42 : Step #900 : NLL Loss: 0.2704966170920266\n",
      "Epoch #42 : Step #1000 : NLL Loss: 0.2677325124144554\n",
      "Epoch #42 : Step #1100 : NLL Loss: 0.26701355210759425\n",
      "Epoch #42 : Step #1200 : NLL Loss: 0.26961639049152536\n",
      "Epoch #42 : Step #1300 : NLL Loss: 0.26757438180538323\n",
      "Epoch #42 : Step #1400 : NLL Loss: 0.2691647799738816\n",
      "Epoch #42 : Step #1500 : NLL Loss: 0.2706191505789757\n",
      "Epoch #42 : Step #1600 : NLL Loss: 0.27094766780734064\n",
      "Epoch #42 : Step #1700 : NLL Loss: 0.26982853395097395\n",
      "Epoch #42 : Step #1800 : NLL Loss: 0.2674276610546642\n",
      "Epoch #42 : Step #1900 : NLL Loss: 0.2677717352070306\n",
      "Epoch #42 : Step #2000 : NLL Loss: 0.26635718159377575\n",
      "Epoch #42 : Step #2100 : NLL Loss: 0.2671909064054489\n",
      "Epoch #42 : Step #2200 : NLL Loss: 0.26799458286978983\n",
      "Epoch #42 : Step #2300 : NLL Loss: 0.2681146546161693\n",
      "Epoch #42 : Step #2400 : NLL Loss: 0.2682372056692839\n",
      "Epoch #42 : Step #2500 : NLL Loss: 0.2688539307594299\n",
      "Epoch #42 : Step #2600 : NLL Loss: 0.2686745091126515\n",
      "Epoch #42 : Step #2700 : NLL Loss: 0.2698607677331677\n",
      "Epoch #42 : Step #2800 : NLL Loss: 0.2704166170741831\n",
      "Epoch #42 : Step #2900 : NLL Loss: 0.27139479528213367\n",
      "Epoch #42 : Step #3000 : NLL Loss: 0.2717542897760868\n",
      "Epoch #42 : Step #3100 : NLL Loss: 0.2713468207466987\n",
      "Loss Epoch #42 : 3188 NLL Loss: 0.27221344849807555\n",
      "\n",
      "Epoch #43 : Step #100 : NLL Loss: 0.25578206837177275\n",
      "Epoch #43 : Step #200 : NLL Loss: 0.27382164299488065\n",
      "Epoch #43 : Step #300 : NLL Loss: 0.2767661941051483\n",
      "Epoch #43 : Step #400 : NLL Loss: 0.2737627141177654\n",
      "Epoch #43 : Step #500 : NLL Loss: 0.2649509241580963\n",
      "Epoch #43 : Step #600 : NLL Loss: 0.2699558666348457\n",
      "Epoch #43 : Step #700 : NLL Loss: 0.26837392185415543\n",
      "Epoch #43 : Step #800 : NLL Loss: 0.2695992008969188\n",
      "Epoch #43 : Step #900 : NLL Loss: 0.27395881556802326\n",
      "Epoch #43 : Step #1000 : NLL Loss: 0.27182643631100656\n",
      "Epoch #43 : Step #1100 : NLL Loss: 0.2725068365714767\n",
      "Epoch #43 : Step #1200 : NLL Loss: 0.27032872175176936\n",
      "Epoch #43 : Step #1300 : NLL Loss: 0.2719843640235754\n",
      "Epoch #43 : Step #1400 : NLL Loss: 0.2724648674258164\n",
      "Epoch #43 : Step #1500 : NLL Loss: 0.27175200154383977\n",
      "Epoch #43 : Step #1600 : NLL Loss: 0.27146863993257286\n",
      "Epoch #43 : Step #1700 : NLL Loss: 0.2705251562770675\n",
      "Epoch #43 : Step #1800 : NLL Loss: 0.26954236540529464\n",
      "Epoch #43 : Step #1900 : NLL Loss: 0.27029941337673286\n",
      "Epoch #43 : Step #2000 : NLL Loss: 0.2709308468699455\n",
      "Epoch #43 : Step #2100 : NLL Loss: 0.2720910161165964\n",
      "Epoch #43 : Step #2200 : NLL Loss: 0.27255203753709795\n",
      "Epoch #43 : Step #2300 : NLL Loss: 0.27203717205835426\n",
      "Epoch #43 : Step #2400 : NLL Loss: 0.27175084508955477\n",
      "Epoch #43 : Step #2500 : NLL Loss: 0.27238126817941666\n",
      "Epoch #43 : Step #2600 : NLL Loss: 0.2720355587395338\n",
      "Epoch #43 : Step #2700 : NLL Loss: 0.27222019895359323\n",
      "Epoch #43 : Step #2800 : NLL Loss: 0.2722478473825114\n",
      "Epoch #43 : Step #2900 : NLL Loss: 0.27145984889104446\n",
      "Epoch #43 : Step #3000 : NLL Loss: 0.27064758868018784\n",
      "Epoch #43 : Step #3100 : NLL Loss: 0.270775785446167\n",
      "Loss Epoch #43 : 3188 NLL Loss: 0.2714972239048448\n",
      "\n",
      "Epoch #44 : Step #100 : NLL Loss: 0.26804232329130173\n",
      "Epoch #44 : Step #200 : NLL Loss: 0.2764224934577942\n",
      "Epoch #44 : Step #300 : NLL Loss: 0.28296843588352205\n",
      "Epoch #44 : Step #400 : NLL Loss: 0.2861093674600124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #44 : Step #500 : NLL Loss: 0.28487668734788896\n",
      "Epoch #44 : Step #600 : NLL Loss: 0.2804603813091914\n",
      "Epoch #44 : Step #700 : NLL Loss: 0.2758538685526167\n",
      "Epoch #44 : Step #800 : NLL Loss: 0.2752643288299441\n",
      "Epoch #44 : Step #900 : NLL Loss: 0.2777780834502644\n",
      "Epoch #44 : Step #1000 : NLL Loss: 0.27688266360759733\n",
      "Epoch #44 : Step #1100 : NLL Loss: 0.2771696314757521\n",
      "Epoch #44 : Step #1200 : NLL Loss: 0.2755589907368024\n",
      "Epoch #44 : Step #1300 : NLL Loss: 0.27399270376333823\n",
      "Epoch #44 : Step #1400 : NLL Loss: 0.2746824594267777\n",
      "Epoch #44 : Step #1500 : NLL Loss: 0.2737137125531832\n",
      "Epoch #44 : Step #1600 : NLL Loss: 0.27443694349378345\n",
      "Epoch #44 : Step #1700 : NLL Loss: 0.27379699994536005\n",
      "Epoch #44 : Step #1800 : NLL Loss: 0.27273143225246005\n",
      "Epoch #44 : Step #1900 : NLL Loss: 0.26964213104624496\n",
      "Epoch #44 : Step #2000 : NLL Loss: 0.2697739043235779\n",
      "Epoch #44 : Step #2100 : NLL Loss: 0.26989519838775905\n",
      "Epoch #44 : Step #2200 : NLL Loss: 0.2708981900188056\n",
      "Epoch #44 : Step #2300 : NLL Loss: 0.27144356550081916\n",
      "Epoch #44 : Step #2400 : NLL Loss: 0.2713580957427621\n",
      "Epoch #44 : Step #2500 : NLL Loss: 0.27135276604890823\n",
      "Epoch #44 : Step #2600 : NLL Loss: 0.2708453946388685\n",
      "Epoch #44 : Step #2700 : NLL Loss: 0.27118250054341775\n",
      "Epoch #44 : Step #2800 : NLL Loss: 0.27140404367021154\n",
      "Epoch #44 : Step #2900 : NLL Loss: 0.27180463231843094\n",
      "Epoch #44 : Step #3000 : NLL Loss: 0.2715733589529991\n",
      "Epoch #44 : Step #3100 : NLL Loss: 0.2711306967369972\n",
      "Loss Epoch #44 : 3188 NLL Loss: 0.2709132112291556\n",
      "\n",
      "Epoch #45 : Step #100 : NLL Loss: 0.2769028228521347\n",
      "Epoch #45 : Step #200 : NLL Loss: 0.2690770247578621\n",
      "Epoch #45 : Step #300 : NLL Loss: 0.2704821478327115\n",
      "Epoch #45 : Step #400 : NLL Loss: 0.27096273012459277\n",
      "Epoch #45 : Step #500 : NLL Loss: 0.27224449133872985\n",
      "Epoch #45 : Step #600 : NLL Loss: 0.2693173841138681\n",
      "Epoch #45 : Step #700 : NLL Loss: 0.27153231752770285\n",
      "Epoch #45 : Step #800 : NLL Loss: 0.2722431719303131\n",
      "Epoch #45 : Step #900 : NLL Loss: 0.2711403945419523\n",
      "Epoch #45 : Step #1000 : NLL Loss: 0.2728661775290966\n",
      "Epoch #45 : Step #1100 : NLL Loss: 0.2700106032328172\n",
      "Epoch #45 : Step #1200 : NLL Loss: 0.2702075057476759\n",
      "Epoch #45 : Step #1300 : NLL Loss: 0.26922698605519074\n",
      "Epoch #45 : Step #1400 : NLL Loss: 0.2693013104583536\n",
      "Epoch #45 : Step #1500 : NLL Loss: 0.2695500657161077\n",
      "Epoch #45 : Step #1600 : NLL Loss: 0.26972174029797313\n",
      "Epoch #45 : Step #1700 : NLL Loss: 0.2699259047823794\n",
      "Epoch #45 : Step #1800 : NLL Loss: 0.27224911957979203\n",
      "Epoch #45 : Step #1900 : NLL Loss: 0.27031823776270214\n",
      "Epoch #45 : Step #2000 : NLL Loss: 0.2687158085107803\n",
      "Epoch #45 : Step #2100 : NLL Loss: 0.2687449672108605\n",
      "Epoch #45 : Step #2200 : NLL Loss: 0.26950935344804416\n",
      "Epoch #45 : Step #2300 : NLL Loss: 0.2698836122388425\n",
      "Epoch #45 : Step #2400 : NLL Loss: 0.26996538545936344\n",
      "Epoch #45 : Step #2500 : NLL Loss: 0.2693544244170189\n",
      "Epoch #45 : Step #2600 : NLL Loss: 0.26984059005975725\n",
      "Epoch #45 : Step #2700 : NLL Loss: 0.269315107177805\n",
      "Epoch #45 : Step #2800 : NLL Loss: 0.26968586746071066\n",
      "Epoch #45 : Step #2900 : NLL Loss: 0.26993337898418823\n",
      "Epoch #45 : Step #3000 : NLL Loss: 0.26962945151329043\n",
      "Epoch #45 : Step #3100 : NLL Loss: 0.270459809322511\n",
      "Loss Epoch #45 : 3188 NLL Loss: 0.27021033837549957\n",
      "\n",
      "Epoch #46 : Step #100 : NLL Loss: 0.2573292702436447\n",
      "Epoch #46 : Step #200 : NLL Loss: 0.2666580331325531\n",
      "Epoch #46 : Step #300 : NLL Loss: 0.27310747375090916\n",
      "Epoch #46 : Step #400 : NLL Loss: 0.2749280961602926\n",
      "Epoch #46 : Step #500 : NLL Loss: 0.26827855563163755\n",
      "Epoch #46 : Step #600 : NLL Loss: 0.2704627616206805\n",
      "Epoch #46 : Step #700 : NLL Loss: 0.26747255759579797\n",
      "Epoch #46 : Step #800 : NLL Loss: 0.2657905443012714\n",
      "Epoch #46 : Step #900 : NLL Loss: 0.2677284688750903\n",
      "Epoch #46 : Step #1000 : NLL Loss: 0.26688089096546175\n",
      "Epoch #46 : Step #1100 : NLL Loss: 0.26812308062206613\n",
      "Epoch #46 : Step #1200 : NLL Loss: 0.269983793720603\n",
      "Epoch #46 : Step #1300 : NLL Loss: 0.2707651346004926\n",
      "Epoch #46 : Step #1400 : NLL Loss: 0.2698824237712792\n",
      "Epoch #46 : Step #1500 : NLL Loss: 0.26961079686880113\n",
      "Epoch #46 : Step #1600 : NLL Loss: 0.2694995297305286\n",
      "Epoch #46 : Step #1700 : NLL Loss: 0.2710175341017106\n",
      "Epoch #46 : Step #1800 : NLL Loss: 0.2696316746373971\n",
      "Epoch #46 : Step #1900 : NLL Loss: 0.26943845719099047\n",
      "Epoch #46 : Step #2000 : NLL Loss: 0.2700620301812887\n",
      "Epoch #46 : Step #2100 : NLL Loss: 0.2693478433007286\n",
      "Epoch #46 : Step #2200 : NLL Loss: 0.2700860466604883\n",
      "Epoch #46 : Step #2300 : NLL Loss: 0.2687204146126042\n",
      "Epoch #46 : Step #2400 : NLL Loss: 0.26786959781001013\n",
      "Epoch #46 : Step #2500 : NLL Loss: 0.2678712879896164\n",
      "Epoch #46 : Step #2600 : NLL Loss: 0.2680389734988029\n",
      "Epoch #46 : Step #2700 : NLL Loss: 0.2686468769113223\n",
      "Epoch #46 : Step #2800 : NLL Loss: 0.2680965327365058\n",
      "Epoch #46 : Step #2900 : NLL Loss: 0.26847955107688903\n",
      "Epoch #46 : Step #3000 : NLL Loss: 0.2689454441567262\n",
      "Epoch #46 : Step #3100 : NLL Loss: 0.26919119543606235\n",
      "Loss Epoch #46 : 3188 NLL Loss: 0.2694754374016034\n",
      "\n",
      "Epoch #47 : Step #100 : NLL Loss: 0.2612626913189888\n",
      "Epoch #47 : Step #200 : NLL Loss: 0.25534006088972094\n",
      "Epoch #47 : Step #300 : NLL Loss: 0.26322154978911083\n",
      "Epoch #47 : Step #400 : NLL Loss: 0.2620519682765007\n",
      "Epoch #47 : Step #500 : NLL Loss: 0.2659329126477242\n",
      "Epoch #47 : Step #600 : NLL Loss: 0.2628052981694539\n",
      "Epoch #47 : Step #700 : NLL Loss: 0.2710288201059614\n",
      "Epoch #47 : Step #800 : NLL Loss: 0.270515303760767\n",
      "Epoch #47 : Step #900 : NLL Loss: 0.27107479833894305\n",
      "Epoch #47 : Step #1000 : NLL Loss: 0.2725624313056469\n",
      "Epoch #47 : Step #1100 : NLL Loss: 0.2702873577042059\n",
      "Epoch #47 : Step #1200 : NLL Loss: 0.26946361052493256\n",
      "Epoch #47 : Step #1300 : NLL Loss: 0.2707208576798439\n",
      "Epoch #47 : Step #1400 : NLL Loss: 0.2692805057125432\n",
      "Epoch #47 : Step #1500 : NLL Loss: 0.2674283991853396\n",
      "Epoch #47 : Step #1600 : NLL Loss: 0.2683703795261681\n",
      "Epoch #47 : Step #1700 : NLL Loss: 0.26914436862749214\n",
      "Epoch #47 : Step #1800 : NLL Loss: 0.27021839724646673\n",
      "Epoch #47 : Step #1900 : NLL Loss: 0.270986695007274\n",
      "Epoch #47 : Step #2000 : NLL Loss: 0.27043435890972617\n",
      "Epoch #47 : Step #2100 : NLL Loss: 0.2697463099871363\n",
      "Epoch #47 : Step #2200 : NLL Loss: 0.2701030345802957\n",
      "Epoch #47 : Step #2300 : NLL Loss: 0.2701003832661587\n",
      "Epoch #47 : Step #2400 : NLL Loss: 0.268975594677031\n",
      "Epoch #47 : Step #2500 : NLL Loss: 0.2689614038467407\n",
      "Epoch #47 : Step #2600 : NLL Loss: 0.2697076327754901\n",
      "Epoch #47 : Step #2700 : NLL Loss: 0.2690796558945267\n",
      "Epoch #47 : Step #2800 : NLL Loss: 0.2693976281051125\n",
      "Epoch #47 : Step #2900 : NLL Loss: 0.26940657240563426\n",
      "Epoch #47 : Step #3000 : NLL Loss: 0.2683441455463568\n",
      "Epoch #47 : Step #3100 : NLL Loss: 0.26903299433569755\n",
      "Loss Epoch #47 : 3188 NLL Loss: 0.2689110137699838\n",
      "\n",
      "Epoch #48 : Step #100 : NLL Loss: 0.2660353410243988\n",
      "Epoch #48 : Step #200 : NLL Loss: 0.26430472642183306\n",
      "Epoch #48 : Step #300 : NLL Loss: 0.2684152653813362\n",
      "Epoch #48 : Step #400 : NLL Loss: 0.2679487168043852\n",
      "Epoch #48 : Step #500 : NLL Loss: 0.2668144779205322\n",
      "Epoch #48 : Step #600 : NLL Loss: 0.267986944715182\n",
      "Epoch #48 : Step #700 : NLL Loss: 0.2639816860641752\n",
      "Epoch #48 : Step #800 : NLL Loss: 0.2638722428306937\n",
      "Epoch #48 : Step #900 : NLL Loss: 0.26399725334511864\n",
      "Epoch #48 : Step #1000 : NLL Loss: 0.26396314880251887\n",
      "Epoch #48 : Step #1100 : NLL Loss: 0.26260433573614467\n",
      "Epoch #48 : Step #1200 : NLL Loss: 0.2660391898949941\n",
      "Epoch #48 : Step #1300 : NLL Loss: 0.2638299323962285\n",
      "Epoch #48 : Step #1400 : NLL Loss: 0.26468878935490336\n",
      "Epoch #48 : Step #1500 : NLL Loss: 0.26703451909621556\n",
      "Epoch #48 : Step #1600 : NLL Loss: 0.26663241198286414\n",
      "Epoch #48 : Step #1700 : NLL Loss: 0.26630239027387953\n",
      "Epoch #48 : Step #1800 : NLL Loss: 0.26597208988335397\n",
      "Epoch #48 : Step #1900 : NLL Loss: 0.2669236171245575\n",
      "Epoch #48 : Step #2000 : NLL Loss: 0.2668501099646092\n",
      "Epoch #48 : Step #2100 : NLL Loss: 0.267060033593859\n",
      "Epoch #48 : Step #2200 : NLL Loss: 0.26766439775174317\n",
      "Epoch #48 : Step #2300 : NLL Loss: 0.268712775564712\n",
      "Epoch #48 : Step #2400 : NLL Loss: 0.2687159895151854\n",
      "Epoch #48 : Step #2500 : NLL Loss: 0.2684518319606781\n",
      "Epoch #48 : Step #2600 : NLL Loss: 0.26861518981365057\n",
      "Epoch #48 : Step #2700 : NLL Loss: 0.2676847866729454\n",
      "Epoch #48 : Step #2800 : NLL Loss: 0.2674561782713447\n",
      "Epoch #48 : Step #2900 : NLL Loss: 0.2677941284097474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #48 : Step #3000 : NLL Loss: 0.26875518080592153\n",
      "Epoch #48 : Step #3100 : NLL Loss: 0.2674621000309144\n",
      "Loss Epoch #48 : 3188 NLL Loss: 0.2683400279156387\n",
      "\n",
      "Epoch #49 : Step #100 : NLL Loss: 0.25882813841104507\n",
      "Epoch #49 : Step #200 : NLL Loss: 0.2674956977367401\n",
      "Epoch #49 : Step #300 : NLL Loss: 0.26706644902626675\n",
      "Epoch #49 : Step #400 : NLL Loss: 0.2619867607206106\n",
      "Epoch #49 : Step #500 : NLL Loss: 0.2668941687941551\n",
      "Epoch #49 : Step #600 : NLL Loss: 0.26126374741395314\n",
      "Epoch #49 : Step #700 : NLL Loss: 0.2629385876229831\n",
      "Epoch #49 : Step #800 : NLL Loss: 0.26294676076620815\n",
      "Epoch #49 : Step #900 : NLL Loss: 0.2610928330818812\n",
      "Epoch #49 : Step #1000 : NLL Loss: 0.2614251511991024\n",
      "Epoch #49 : Step #1100 : NLL Loss: 0.2633780268647454\n",
      "Epoch #49 : Step #1200 : NLL Loss: 0.2626944573720296\n",
      "Epoch #49 : Step #1300 : NLL Loss: 0.26206786112143443\n",
      "Epoch #49 : Step #1400 : NLL Loss: 0.2631879593006202\n",
      "Epoch #49 : Step #1500 : NLL Loss: 0.26512648129463195\n",
      "Epoch #49 : Step #1600 : NLL Loss: 0.26532075002789496\n",
      "Epoch #49 : Step #1700 : NLL Loss: 0.26522310760091333\n",
      "Epoch #49 : Step #1800 : NLL Loss: 0.2658206603758865\n",
      "Epoch #49 : Step #1900 : NLL Loss: 0.2663341257603545\n",
      "Epoch #49 : Step #2000 : NLL Loss: 0.26758731265366076\n",
      "Epoch #49 : Step #2100 : NLL Loss: 0.26757566050404596\n",
      "Epoch #49 : Step #2200 : NLL Loss: 0.2677885759554126\n",
      "Epoch #49 : Step #2300 : NLL Loss: 0.26802276541357456\n",
      "Epoch #49 : Step #2400 : NLL Loss: 0.2666146641721328\n",
      "Epoch #49 : Step #2500 : NLL Loss: 0.26731604301929474\n",
      "Epoch #49 : Step #2600 : NLL Loss: 0.2670641541710267\n",
      "Epoch #49 : Step #2700 : NLL Loss: 0.2665319707879314\n",
      "Epoch #49 : Step #2800 : NLL Loss: 0.2659137227279799\n",
      "Epoch #49 : Step #2900 : NLL Loss: 0.26647596511347543\n",
      "Epoch #49 : Step #3000 : NLL Loss: 0.2678175263404846\n",
      "Epoch #49 : Step #3100 : NLL Loss: 0.2673301946443896\n",
      "Loss Epoch #49 : 3188 NLL Loss: 0.26768585237460574\n",
      "\n",
      "Epoch #50 : Step #100 : NLL Loss: 0.251681994497776\n",
      "Epoch #50 : Step #200 : NLL Loss: 0.2552068357169628\n",
      "Epoch #50 : Step #300 : NLL Loss: 0.2521509349346161\n",
      "Epoch #50 : Step #400 : NLL Loss: 0.2584147420525551\n",
      "Epoch #50 : Step #500 : NLL Loss: 0.2584761969447136\n",
      "Epoch #50 : Step #600 : NLL Loss: 0.25910931726296743\n",
      "Epoch #50 : Step #700 : NLL Loss: 0.26019081260476795\n",
      "Epoch #50 : Step #800 : NLL Loss: 0.25988411888480184\n",
      "Epoch #50 : Step #900 : NLL Loss: 0.2619979008369976\n",
      "Epoch #50 : Step #1000 : NLL Loss: 0.2610501135289669\n",
      "Epoch #50 : Step #1100 : NLL Loss: 0.26310645425861534\n",
      "Epoch #50 : Step #1200 : NLL Loss: 0.2638785597930352\n",
      "Epoch #50 : Step #1300 : NLL Loss: 0.264576120537061\n",
      "Epoch #50 : Step #1400 : NLL Loss: 0.2641870556558881\n",
      "Epoch #50 : Step #1500 : NLL Loss: 0.2631435489257177\n",
      "Epoch #50 : Step #1600 : NLL Loss: 0.2640804113261402\n",
      "Epoch #50 : Step #1700 : NLL Loss: 0.2650885050261722\n",
      "Epoch #50 : Step #1800 : NLL Loss: 0.2652644167840481\n",
      "Epoch #50 : Step #1900 : NLL Loss: 0.2646865144685695\n",
      "Epoch #50 : Step #2000 : NLL Loss: 0.26403582222759725\n",
      "Epoch #50 : Step #2100 : NLL Loss: 0.26524940839835576\n",
      "Epoch #50 : Step #2200 : NLL Loss: 0.2655477180264213\n",
      "Epoch #50 : Step #2300 : NLL Loss: 0.26502726946188054\n",
      "Epoch #50 : Step #2400 : NLL Loss: 0.2648685112719735\n",
      "Epoch #50 : Step #2500 : NLL Loss: 0.2652606453180313\n",
      "Epoch #50 : Step #2600 : NLL Loss: 0.2656321091720691\n",
      "Epoch #50 : Step #2700 : NLL Loss: 0.26710132262221087\n",
      "Epoch #50 : Step #2800 : NLL Loss: 0.26789331447865283\n",
      "Epoch #50 : Step #2900 : NLL Loss: 0.2675255277547343\n",
      "Epoch #50 : Step #3000 : NLL Loss: 0.2672776865065098\n",
      "Epoch #50 : Step #3100 : NLL Loss: 0.26727976394276465\n",
      "Loss Epoch #50 : 3188 NLL Loss: 0.2673158908970981\n",
      "\n",
      "Testing.......\n",
      "\n",
      "Test Results: NLL Loss: 0.26829064, Accuracy: 0.8908888888888888"
     ]
    }
   ],
   "source": [
    "PPLM.train_discriminator(text_reduced, label_reduced, 8, \"Multiclass\", 2; lr=5e-6, discrim=discrim, tokenizer=tokenizer, args=args, train_size=0.85, epochs=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ecaf3",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fea58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = PPLM.splitobs((text_reduced, label_reduced); at=0.8)\n",
    "        \n",
    "train_loader = PPLM.load_cached_data(discrim, train_x, train_y, tokenizer; truncate=true, classification_type=\"Multiclass\");\n",
    "\n",
    "test_loader = PPLM.load_cached_data(discrim, test_x, test_y, tokenizer; truncate=true, classification_type=\"Multiclass\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23811fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting.........\n",
      "\n",
      "Epoch #1 : Step #100 : NLL Loss: 1.9753262543678283\n",
      "Epoch #1 : Step #200 : NLL Loss: 1.9231716027855874\n",
      "Epoch #1 : Step #300 : NLL Loss: 1.8749549571673076\n",
      "Epoch #1 : Step #400 : NLL Loss: 1.8426343695819378\n",
      "Epoch #1 : Step #500 : NLL Loss: 1.8339375865459442\n",
      "Epoch #1 : Step #600 : NLL Loss: 1.7932911743720372\n",
      "Epoch #1 : Step #700 : NLL Loss: 1.7661278000899723\n",
      "Epoch #1 : Step #800 : NLL Loss: 1.7534843473881483\n",
      "Epoch #1 : Step #900 : NLL Loss: 1.7093081312709384\n",
      "Epoch #1 : Step #1000 : NLL Loss: 1.6702592520415782\n",
      "Epoch #1 : Step #1100 : NLL Loss: 1.6479249478199265\n",
      "Epoch #1 : Step #1200 : NLL Loss: 1.6145438824842373\n",
      "Epoch #1 : Step #1300 : NLL Loss: 1.5371075125267872\n",
      "Epoch #1 : Step #1400 : NLL Loss: 1.4313458395696113\n",
      "Epoch #1 : Step #1500 : NLL Loss: 1.3402320544868707\n",
      "Epoch #1 : Step #1600 : NLL Loss: 1.2606613345770166\n",
      "Epoch #1 : Step #1700 : NLL Loss: 1.1902108608580688\n",
      "Epoch #1 : Step #1800 : NLL Loss: 1.1275494936646686\n",
      "Epoch #1 : Step #1900 : NLL Loss: 1.0708832943321842\n",
      "Epoch #1 : Step #2000 : NLL Loss: 1.020372696183622\n",
      "Epoch #1 : Step #2100 : NLL Loss: 0.974495105239607\n",
      "Epoch #1 : Step #2200 : NLL Loss: 0.9326916858282956\n",
      "Epoch #1 : Step #2300 : NLL Loss: 0.8949472391540589\n",
      "Epoch #1 : Step #2400 : NLL Loss: 0.8601432753540575\n",
      "Epoch #1 : Step #2500 : NLL Loss: 0.8277390625730157\n",
      "Loss Epoch #1 : 2500 NLL Loss: 0.8277390625730157\n",
      "\n",
      "Epoch #2 : Step #100 : NLL Loss: 1.2707816791534423\n",
      "Epoch #2 : Step #200 : NLL Loss: 1.2127025420963764\n",
      "Epoch #2 : Step #300 : NLL Loss: 1.159708634118239\n",
      "Epoch #2 : Step #400 : NLL Loss: 1.1228600415587424\n",
      "Epoch #2 : Step #500 : NLL Loss: 1.1040909579992295\n",
      "Epoch #2 : Step #600 : NLL Loss: 1.0660351581374805\n",
      "Epoch #2 : Step #700 : NLL Loss: 1.0395635673829486\n",
      "Epoch #2 : Step #800 : NLL Loss: 1.0257037686556578\n",
      "Epoch #2 : Step #900 : NLL Loss: 0.9900024537245432\n",
      "Epoch #2 : Step #1000 : NLL Loss: 0.9585510773360729\n",
      "Epoch #2 : Step #1100 : NLL Loss: 0.9388995782895522\n",
      "Epoch #2 : Step #1200 : NLL Loss: 0.9133493397384882\n",
      "Epoch #2 : Step #1300 : NLL Loss: 0.8724288691637607\n",
      "Epoch #2 : Step #1400 : NLL Loss: 0.8213587218363371\n",
      "Epoch #2 : Step #1500 : NLL Loss: 0.7779774917413791\n",
      "Epoch #2 : Step #1600 : NLL Loss: 0.7394192860508337\n",
      "Epoch #2 : Step #1700 : NLL Loss: 0.70564458347857\n",
      "Epoch #2 : Step #1800 : NLL Loss: 0.6749373183151086\n",
      "Epoch #2 : Step #1900 : NLL Loss: 0.6463281394462836\n",
      "Epoch #2 : Step #2000 : NLL Loss: 0.6213627892769873\n",
      "Epoch #2 : Step #2100 : NLL Loss: 0.5983331484418539\n",
      "Epoch #2 : Step #2200 : NLL Loss: 0.5772268794714049\n",
      "Epoch #2 : Step #2300 : NLL Loss: 0.5582894691144643\n",
      "Epoch #2 : Step #2400 : NLL Loss: 0.5405603652788947\n",
      "Epoch #2 : Step #2500 : NLL Loss: 0.5235889406472445\n",
      "Loss Epoch #2 : 2500 NLL Loss: 0.5235889406472445\n",
      "\n",
      "Epoch #3 : Step #100 : NLL Loss: 0.7627224576473236\n",
      "Epoch #3 : Step #200 : NLL Loss: 0.7252406206727028\n",
      "Epoch #3 : Step #300 : NLL Loss: 0.6887729659676551\n",
      "Epoch #3 : Step #400 : NLL Loss: 0.6641406370699405\n",
      "Epoch #3 : Step #500 : NLL Loss: 0.6522731697559356\n",
      "Epoch #3 : Step #600 : NLL Loss: 0.6275843031704426\n",
      "Epoch #3 : Step #700 : NLL Loss: 0.6111191163318498\n",
      "Epoch #3 : Step #800 : NLL Loss: 0.6033744401857257\n",
      "Epoch #3 : Step #900 : NLL Loss: 0.5806082710954878\n",
      "Epoch #3 : Step #1000 : NLL Loss: 0.5605285781919956\n",
      "Epoch #3 : Step #1100 : NLL Loss: 0.5482780728692358\n",
      "Epoch #3 : Step #1200 : NLL Loss: 0.5323230881616473\n",
      "Epoch #3 : Step #1300 : NLL Loss: 0.5174676453035612\n",
      "Epoch #3 : Step #1400 : NLL Loss: 0.5016538732392447\n",
      "Epoch #3 : Step #1500 : NLL Loss: 0.48847176555792493\n",
      "Epoch #3 : Step #1600 : NLL Loss: 0.4751499967649579\n",
      "Epoch #3 : Step #1700 : NLL Loss: 0.4639379680857939\n",
      "Epoch #3 : Step #1800 : NLL Loss: 0.4521841177675459\n",
      "Epoch #3 : Step #1900 : NLL Loss: 0.4399618801631426\n",
      "Epoch #3 : Step #2000 : NLL Loss: 0.42981245762109754\n",
      "Epoch #3 : Step #2100 : NLL Loss: 0.4197317100422723\n",
      "Epoch #3 : Step #2200 : NLL Loss: 0.41020589102398264\n",
      "Epoch #3 : Step #2300 : NLL Loss: 0.40149814041412396\n",
      "Epoch #3 : Step #2400 : NLL Loss: 0.3929749119716386\n",
      "Epoch #3 : Step #2500 : NLL Loss: 0.38422222070395945\n",
      "Loss Epoch #3 : 2500 NLL Loss: 0.38422222070395945\n",
      "\n",
      "Epoch #4 : Step #100 : NLL Loss: 0.5669413918256759\n",
      "Epoch #4 : Step #200 : NLL Loss: 0.5393345938250422\n",
      "Epoch #4 : Step #300 : NLL Loss: 0.5112841483702262\n",
      "Epoch #4 : Step #400 : NLL Loss: 0.49271063787862657\n",
      "Epoch #4 : Step #500 : NLL Loss: 0.4844578209966421\n",
      "Epoch #4 : Step #600 : NLL Loss: 0.46589424221465986\n",
      "Epoch #4 : Step #700 : NLL Loss: 0.45389100797474385\n",
      "Epoch #4 : Step #800 : NLL Loss: 0.4487147904466838\n",
      "Epoch #4 : Step #900 : NLL Loss: 0.431466285975443\n",
      "Epoch #4 : Step #1000 : NLL Loss: 0.4162358864620328\n",
      "Epoch #4 : Step #1100 : NLL Loss: 0.40717960002070125\n",
      "Epoch #4 : Step #1200 : NLL Loss: 0.39517553785815834\n",
      "Epoch #4 : Step #1300 : NLL Loss: 0.3918356804091197\n",
      "Epoch #4 : Step #1400 : NLL Loss: 0.3915927777439356\n",
      "Epoch #4 : Step #1500 : NLL Loss: 0.3912890624701977\n",
      "Epoch #4 : Step #1600 : NLL Loss: 0.38837658730335534\n",
      "Epoch #4 : Step #1700 : NLL Loss: 0.38634805890567164\n",
      "Epoch #4 : Step #1800 : NLL Loss: 0.382003268458777\n",
      "Epoch #4 : Step #1900 : NLL Loss: 0.37606843072332835\n",
      "Epoch #4 : Step #2000 : NLL Loss: 0.37154649540036916\n",
      "Epoch #4 : Step #2100 : NLL Loss: 0.3662633689457462\n",
      "Epoch #4 : Step #2200 : NLL Loss: 0.3609638162024997\n",
      "Epoch #4 : Step #2300 : NLL Loss: 0.35589417412877083\n",
      "Epoch #4 : Step #2400 : NLL Loss: 0.35062056514744955\n",
      "Epoch #4 : Step #2500 : NLL Loss: 0.34473236473202706\n",
      "Loss Epoch #4 : 2500 NLL Loss: 0.34473236473202706\n",
      "\n",
      "Epoch #5 : Step #100 : NLL Loss: 0.4995678034424782\n",
      "Epoch #5 : Step #200 : NLL Loss: 0.4762054689414799\n",
      "Epoch #5 : Step #300 : NLL Loss: 0.4517511408155163\n",
      "Epoch #5 : Step #400 : NLL Loss: 0.43578359805978834\n",
      "Epoch #5 : Step #500 : NLL Loss: 0.42918311316519975\n",
      "Epoch #5 : Step #600 : NLL Loss: 0.4130388519726694\n",
      "Epoch #5 : Step #700 : NLL Loss: 0.4027973470570786\n",
      "Epoch #5 : Step #800 : NLL Loss: 0.398716860790737\n",
      "Epoch #5 : Step #900 : NLL Loss: 0.3834971458423469\n",
      "Epoch #5 : Step #1000 : NLL Loss: 0.3700442221052945\n",
      "Epoch #5 : Step #1100 : NLL Loss: 0.3622053819522262\n",
      "Epoch #5 : Step #1200 : NLL Loss: 0.35162392066481213\n",
      "Epoch #5 : Step #1300 : NLL Loss: 0.35230054151266815\n",
      "Epoch #5 : Step #1400 : NLL Loss: 0.3574293433316052\n",
      "Epoch #5 : Step #1500 : NLL Loss: 0.36150088951736686\n",
      "Epoch #5 : Step #1600 : NLL Loss: 0.3620720470859669\n",
      "Epoch #5 : Step #1700 : NLL Loss: 0.3631094841900117\n",
      "Epoch #5 : Step #1800 : NLL Loss: 0.3611987680176066\n",
      "Epoch #5 : Step #1900 : NLL Loss: 0.3573162235378435\n",
      "Epoch #5 : Step #2000 : NLL Loss: 0.3546323560308665\n",
      "Epoch #5 : Step #2100 : NLL Loss: 0.3509068415118825\n",
      "Epoch #5 : Step #2200 : NLL Loss: 0.3469721950302747\n",
      "Epoch #5 : Step #2300 : NLL Loss: 0.34306751840626415\n",
      "Epoch #5 : Step #2400 : NLL Loss: 0.3388361162800963\n",
      "Epoch #5 : Step #2500 : NLL Loss: 0.3338620719358325\n",
      "Loss Epoch #5 : 2500 NLL Loss: 0.3338620719358325\n",
      "\n",
      "Epoch #6 : Step #100 : NLL Loss: 0.47634491831064224\n",
      "Epoch #6 : Step #200 : NLL Loss: 0.4546570649370551\n",
      "Epoch #6 : Step #300 : NLL Loss: 0.43156989239156246\n",
      "Epoch #6 : Step #400 : NLL Loss: 0.41659649619832634\n",
      "Epoch #6 : Step #500 : NLL Loss: 0.4106547214537859\n",
      "Epoch #6 : Step #600 : NLL Loss: 0.39540862169116736\n",
      "Epoch #6 : Step #700 : NLL Loss: 0.3858165967145136\n",
      "Epoch #6 : Step #800 : NLL Loss: 0.38217625656165183\n",
      "Epoch #6 : Step #900 : NLL Loss: 0.367684397076567\n",
      "Epoch #6 : Step #1000 : NLL Loss: 0.3548697239495814\n",
      "Epoch #6 : Step #1100 : NLL Loss: 0.347481097291139\n",
      "Epoch #6 : Step #1200 : NLL Loss: 0.33740432349033656\n",
      "Epoch #6 : Step #1300 : NLL Loss: 0.3393799399212003\n",
      "Epoch #6 : Step #1400 : NLL Loss: 0.3462057564434196\n",
      "Epoch #6 : Step #1500 : NLL Loss: 0.35167322619011004\n",
      "Epoch #6 : Step #1600 : NLL Loss: 0.35334948322968557\n",
      "Epoch #6 : Step #1700 : NLL Loss: 0.355372460057192\n",
      "Epoch #6 : Step #1800 : NLL Loss: 0.35424227051643864\n",
      "Epoch #6 : Step #1900 : NLL Loss: 0.35101658108399103\n",
      "Epoch #6 : Step #2000 : NLL Loss: 0.3489265396762639\n",
      "Epoch #6 : Step #2100 : NLL Loss: 0.3457095337783297\n",
      "Epoch #6 : Step #2200 : NLL Loss: 0.34221903425895356\n",
      "Epoch #6 : Step #2300 : NLL Loss: 0.3386958733087648\n",
      "Epoch #6 : Step #2400 : NLL Loss: 0.33480871971851833\n",
      "Epoch #6 : Step #2500 : NLL Loss: 0.33013622790127994\n",
      "Loss Epoch #6 : 2500 NLL Loss: 0.33013622790127994\n",
      "\n",
      "Epoch #7 : Step #100 : NLL Loss: 0.46790462613105777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7 : Step #200 : NLL Loss: 0.44689521230757234\n",
      "Epoch #7 : Step #300 : NLL Loss: 0.42431444600224494\n",
      "Epoch #7 : Step #400 : NLL Loss: 0.4097029895707965\n",
      "Epoch #7 : Step #500 : NLL Loss: 0.4040096550285816\n",
      "Epoch #7 : Step #600 : NLL Loss: 0.3890973145514727\n",
      "Epoch #7 : Step #700 : NLL Loss: 0.3797350714675018\n",
      "Epoch #7 : Step #800 : NLL Loss: 0.37626804592087865\n",
      "Epoch #7 : Step #900 : NLL Loss: 0.36204471967286533\n",
      "Epoch #7 : Step #1000 : NLL Loss: 0.3494673364497721\n",
      "Epoch #7 : Step #1100 : NLL Loss: 0.3422479705072262\n",
      "Epoch #7 : Step #1200 : NLL Loss: 0.3323555577515314\n",
      "Epoch #7 : Step #1300 : NLL Loss: 0.33474427888313163\n",
      "Epoch #7 : Step #1400 : NLL Loss: 0.3420818977723164\n",
      "Epoch #7 : Step #1500 : NLL Loss: 0.347988312723736\n",
      "Epoch #7 : Step #1600 : NLL Loss: 0.3500071258866228\n",
      "Epoch #7 : Step #1700 : NLL Loss: 0.35234835523235447\n",
      "Epoch #7 : Step #1800 : NLL Loss: 0.3514699290630718\n",
      "Epoch #7 : Step #1900 : NLL Loss: 0.3484545923318518\n",
      "Epoch #7 : Step #2000 : NLL Loss: 0.3465593778733164\n",
      "Epoch #7 : Step #2100 : NLL Loss: 0.3435149710820544\n",
      "Epoch #7 : Step #2200 : NLL Loss: 0.34017364342273637\n",
      "Epoch #7 : Step #2300 : NLL Loss: 0.3367819278671042\n",
      "Epoch #7 : Step #2400 : NLL Loss: 0.3330158490206425\n",
      "Epoch #7 : Step #2500 : NLL Loss: 0.32844915822893384\n",
      "Loss Epoch #7 : 2500 NLL Loss: 0.32844915822893384\n",
      "\n",
      "Epoch #8 : Step #100 : NLL Loss: 0.46432385116815567\n",
      "Epoch #8 : Step #200 : NLL Loss: 0.4436468104273081\n",
      "Epoch #8 : Step #300 : NLL Loss: 0.421274731506904\n",
      "Epoch #8 : Step #400 : NLL Loss: 0.40680501352995635\n",
      "Epoch #8 : Step #500 : NLL Loss: 0.4012140404880047\n",
      "Epoch #8 : Step #600 : NLL Loss: 0.3864425691217184\n",
      "Epoch #8 : Step #700 : NLL Loss: 0.377165720398937\n",
      "Epoch #8 : Step #800 : NLL Loss: 0.3737773117609322\n",
      "Epoch #8 : Step #900 : NLL Loss: 0.35966801184746955\n",
      "Epoch #8 : Step #1000 : NLL Loss: 0.3471931146457791\n",
      "Epoch #8 : Step #1100 : NLL Loss: 0.3400469770282507\n",
      "Epoch #8 : Step #1200 : NLL Loss: 0.330231467615813\n",
      "Epoch #8 : Step #1300 : NLL Loss: 0.33274865745351867\n",
      "Epoch #8 : Step #1400 : NLL Loss: 0.34021986590964454\n",
      "Epoch #8 : Step #1500 : NLL Loss: 0.3462592387199402\n",
      "Epoch #8 : Step #1600 : NLL Loss: 0.34837672535330055\n",
      "Epoch #8 : Step #1700 : NLL Loss: 0.3508224369147245\n",
      "Epoch #8 : Step #1800 : NLL Loss: 0.35002622324559424\n",
      "Epoch #8 : Step #1900 : NLL Loss: 0.3470780136553865\n",
      "Epoch #8 : Step #2000 : NLL Loss: 0.3452494454830885\n",
      "Epoch #8 : Step #2100 : NLL Loss: 0.34226966676967485\n",
      "Epoch #8 : Step #2200 : NLL Loss: 0.3389827364886349\n",
      "Epoch #8 : Step #2300 : NLL Loss: 0.33564202631945195\n",
      "Epoch #8 : Step #2400 : NLL Loss: 0.33192521285886567\n",
      "Epoch #8 : Step #2500 : NLL Loss: 0.3274013403713703\n",
      "Loss Epoch #8 : 2500 NLL Loss: 0.3274013403713703\n",
      "\n",
      "Epoch #9 : Step #100 : NLL Loss: 0.4623263159394264\n",
      "Epoch #9 : Step #200 : NLL Loss: 0.44186416525393724\n",
      "Epoch #9 : Step #300 : NLL Loss: 0.4196025154739618\n",
      "Epoch #9 : Step #400 : NLL Loss: 0.40520170049741866\n",
      "Epoch #9 : Step #500 : NLL Loss: 0.3996645146161318\n",
      "Epoch #9 : Step #600 : NLL Loss: 0.3849701985344291\n",
      "Epoch #9 : Step #700 : NLL Loss: 0.3757307097422225\n",
      "Epoch #9 : Step #800 : NLL Loss: 0.3723889437038451\n",
      "Epoch #9 : Step #900 : NLL Loss: 0.3583428385936552\n",
      "Epoch #9 : Step #1000 : NLL Loss: 0.34592611810937524\n",
      "Epoch #9 : Step #1100 : NLL Loss: 0.3388216004080393\n",
      "Epoch #9 : Step #1200 : NLL Loss: 0.3290478492683421\n",
      "Epoch #9 : Step #1300 : NLL Loss: 0.33160265805916145\n",
      "Epoch #9 : Step #1400 : NLL Loss: 0.3390876423168395\n",
      "Epoch #9 : Step #1500 : NLL Loss: 0.3451627124672135\n",
      "Epoch #9 : Step #1600 : NLL Loss: 0.34730136887403207\n",
      "Epoch #9 : Step #1700 : NLL Loss: 0.34978342488627223\n",
      "Epoch #9 : Step #1800 : NLL Loss: 0.3490153284391595\n",
      "Epoch #9 : Step #1900 : NLL Loss: 0.34608858455364644\n",
      "Epoch #9 : Step #2000 : NLL Loss: 0.34428571960516274\n",
      "Epoch #9 : Step #2100 : NLL Loss: 0.3413359195011712\n",
      "Epoch #9 : Step #2200 : NLL Loss: 0.3380729978887195\n",
      "Epoch #9 : Step #2300 : NLL Loss: 0.33475743054209844\n",
      "Epoch #9 : Step #2400 : NLL Loss: 0.3310667375739043\n",
      "Epoch #9 : Step #2500 : NLL Loss: 0.3265653505936265\n",
      "Loss Epoch #9 : 2500 NLL Loss: 0.3265653505936265\n",
      "\n",
      "Epoch #10 : Step #100 : NLL Loss: 0.46085374504327775\n",
      "Epoch #10 : Step #200 : NLL Loss: 0.4405671363323927\n",
      "Epoch #10 : Step #300 : NLL Loss: 0.41838367775082586\n",
      "Epoch #10 : Step #400 : NLL Loss: 0.40402797583490613\n",
      "Epoch #10 : Step #500 : NLL Loss: 0.39852876088023187\n",
      "Epoch #10 : Step #600 : NLL Loss: 0.3838907929013173\n",
      "Epoch #10 : Step #700 : NLL Loss: 0.37467321206416404\n",
      "Epoch #10 : Step #800 : NLL Loss: 0.3713676826097071\n",
      "Epoch #10 : Step #900 : NLL Loss: 0.35736802238557075\n",
      "Epoch #10 : Step #1000 : NLL Loss: 0.34499477287381886\n",
      "Epoch #10 : Step #1100 : NLL Loss: 0.33792150143872607\n",
      "Epoch #10 : Step #1200 : NLL Loss: 0.3281778535867731\n",
      "Epoch #10 : Step #1300 : NLL Loss: 0.3307408119394229\n",
      "Epoch #10 : Step #1400 : NLL Loss: 0.33820110611617565\n",
      "Epoch #10 : Step #1500 : NLL Loss: 0.3442802085975806\n",
      "Epoch #10 : Step #1600 : NLL Loss: 0.346414831886068\n",
      "Epoch #10 : Step #1700 : NLL Loss: 0.3489110797731315\n",
      "Epoch #10 : Step #1800 : NLL Loss: 0.34815343067877824\n",
      "Epoch #10 : Step #1900 : NLL Loss: 0.3452332622675519\n",
      "Epoch #10 : Step #2000 : NLL Loss: 0.3434426908791065\n",
      "Epoch #10 : Step #2100 : NLL Loss: 0.340511416473559\n",
      "Epoch #10 : Step #2200 : NLL Loss: 0.33726249152286486\n",
      "Epoch #10 : Step #2300 : NLL Loss: 0.3339634730828845\n",
      "Epoch #10 : Step #2400 : NLL Loss: 0.33029123645896713\n",
      "Epoch #10 : Step #2500 : NLL Loss: 0.3258055748164654\n",
      "Loss Epoch #10 : 2500 NLL Loss: 0.3258055748164654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PPLM.train!(discrim, train_loader; args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPLM.test!(discrim, test_loader; args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f654e5",
   "metadata": {},
   "source": [
    "# Save Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c44ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving classifier head weights for the discriminator to /home/adarshkumar712/Projects/PPLM_1/src/./pretrained_discriminators/toxicity_classifier_head_768.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Saving classifier without Hyperparameter information\n",
      "└ @ PPLM /home/adarshkumar712/Projects/PPLM_1/src/discriminator.jl:133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator saved successfully"
     ]
    }
   ],
   "source": [
    "PPLM.save_discriminator(discrim, \"toxicity\"; file_name=\"toxicity_classifier_head_768.bson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7047e3a",
   "metadata": {},
   "source": [
    "# Load the saved Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4433904",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim = PPLM.get_discriminator(model; load_from_pretrained=true, discrim=\"toxicity\", class_size=2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
